{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5516eea0",
   "metadata": {},
   "source": [
    "# Red Neuronal con Embeddings para Variables Categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0cf880",
   "metadata": {},
   "source": [
    "\n",
    "Este notebook reemplaza el uso de `OneHotEncoder` por capas de `Embedding` para procesar variables categóricas (como `ocean_proximity`), lo que permite:\n",
    "\n",
    "- Reducir dimensionalidad.\n",
    "- Capturar relaciones semánticas entre categorías.\n",
    "- Mejorar el rendimiento de la red neuronal al tratar con datos mixtos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13691f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Usando dispositivo:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60ebc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "housing = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "# Separar variable categórica\n",
    "cat_col = \"ocean_proximity\"\n",
    "housing[cat_col] = housing[cat_col].astype(\"category\")\n",
    "housing[\"cat_code\"] = housing[cat_col].cat.codes\n",
    "\n",
    "# Variables numéricas\n",
    "X_num = housing.drop([\"median_house_value\", \"ocean_proximity\", \"cat_code\"], axis=1)\n",
    "X_cat = housing[\"cat_code\"]\n",
    "y = housing[\"median_house_value\"]\n",
    "\n",
    "# División\n",
    "X_train_num, X_test_num, X_train_cat, X_test_cat, y_train, y_test = train_test_split(\n",
    "    X_num, X_cat, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_num, X_valid_num, X_train_cat, X_valid_cat, y_train, y_valid = train_test_split(\n",
    "    X_train_num, X_train_cat, y_train, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66dccb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).astype(np.float32)\n",
    "y_valid_scaled = y_scaler.transform(y_valid.values.reshape(-1, 1)).astype(np.float32)\n",
    "y_test_scaled = y_scaler.transform(y_test.values.reshape(-1, 1)).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9f5591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_num_scaled = scaler.fit_transform(X_train_num).astype(np.float32)\n",
    "X_valid_num_scaled = scaler.transform(X_valid_num).astype(np.float32)\n",
    "X_test_num_scaled = scaler.transform(X_test_num).astype(np.float32)\n",
    "\n",
    "X_train_cat_tensor = torch.tensor(X_train_cat.values).long()\n",
    "X_valid_cat_tensor = torch.tensor(X_valid_cat.values).long()\n",
    "X_test_cat_tensor = torch.tensor(X_test_cat.values).long()\n",
    "\n",
    "X_train_num_tensor = torch.tensor(X_train_num_scaled)\n",
    "X_valid_num_tensor = torch.tensor(X_valid_num_scaled).to(device)\n",
    "X_test_num_tensor = torch.tensor(X_test_num_scaled).to(device)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train_scaled)\n",
    "y_valid_tensor = torch.tensor(y_valid_scaled).to(device)\n",
    "y_test_tensor = torch.tensor(y_test_scaled).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff3fd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_num_tensor, X_train_cat_tensor, y_train_tensor),\n",
    "    batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717744d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HousingEmbeddingNet(nn.Module):\n",
    "    def __init__(self, input_dim_num, num_categories, emb_dim=4):\n",
    "        super(HousingEmbeddingNet, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_categories, emb_dim)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim_num + emb_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_cat):\n",
    "        emb = self.embedding(x_cat)\n",
    "        x = torch.cat([x_num, emb], dim=1)\n",
    "        return self.net(x)\n",
    "\n",
    "num_features = X_train_num_tensor.shape[1]\n",
    "num_categories = housing[\"cat_code\"].nunique()\n",
    "model = HousingEmbeddingNet(num_features, num_categories).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4377e982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Val RMSE: 67863.19\n",
      "Epoch 2, Val RMSE: 62753.27\n",
      "Epoch 3, Val RMSE: 61044.99\n",
      "Epoch 4, Val RMSE: 60093.47\n",
      "Epoch 5, Val RMSE: 59741.15\n",
      "Epoch 6, Val RMSE: 58550.53\n",
      "Epoch 7, Val RMSE: 58441.05\n",
      "Epoch 8, Val RMSE: 58918.68\n",
      "Epoch 9, Val RMSE: 57955.90\n",
      "Epoch 10, Val RMSE: 57890.49\n",
      "Epoch 11, Val RMSE: 57669.88\n",
      "Epoch 12, Val RMSE: 57861.23\n",
      "Epoch 13, Val RMSE: 57253.61\n",
      "Epoch 14, Val RMSE: 57099.10\n",
      "Epoch 15, Val RMSE: 56614.00\n",
      "Epoch 16, Val RMSE: 57137.00\n",
      "Epoch 17, Val RMSE: 55971.24\n",
      "Epoch 18, Val RMSE: 56057.27\n",
      "Epoch 19, Val RMSE: 56032.55\n",
      "Epoch 20, Val RMSE: 55844.40\n",
      "Epoch 21, Val RMSE: 56521.13\n",
      "Epoch 22, Val RMSE: 56041.60\n",
      "Epoch 23, Val RMSE: 55379.55\n",
      "Epoch 24, Val RMSE: 55260.92\n",
      "Epoch 25, Val RMSE: 55973.83\n",
      "Epoch 26, Val RMSE: 55648.82\n",
      "Epoch 27, Val RMSE: 54858.26\n",
      "Epoch 28, Val RMSE: 54849.15\n",
      "Epoch 29, Val RMSE: 54303.07\n",
      "Epoch 30, Val RMSE: 54517.49\n",
      "Epoch 31, Val RMSE: 54496.89\n",
      "Epoch 32, Val RMSE: 54264.53\n",
      "Epoch 33, Val RMSE: 54588.81\n",
      "Epoch 34, Val RMSE: 55032.39\n",
      "Epoch 35, Val RMSE: 53905.74\n",
      "Epoch 36, Val RMSE: 54833.27\n",
      "Epoch 37, Val RMSE: 53897.54\n",
      "Epoch 38, Val RMSE: 53506.83\n",
      "Epoch 39, Val RMSE: 53831.86\n",
      "Epoch 40, Val RMSE: 54035.56\n",
      "Epoch 41, Val RMSE: 54538.96\n",
      "Epoch 42, Val RMSE: 54100.49\n",
      "Epoch 43, Val RMSE: 54175.89\n",
      "Epoch 44, Val RMSE: 53674.95\n",
      "Epoch 45, Val RMSE: 54071.10\n",
      "Epoch 46, Val RMSE: 53222.63\n",
      "Epoch 47, Val RMSE: 54115.35\n",
      "Epoch 48, Val RMSE: 53244.89\n",
      "Epoch 49, Val RMSE: 54036.32\n",
      "Epoch 50, Val RMSE: 53849.14\n",
      "Epoch 51, Val RMSE: 53453.56\n",
      "Epoch 52, Val RMSE: 53112.96\n",
      "Epoch 53, Val RMSE: 52973.72\n",
      "Epoch 54, Val RMSE: 53441.07\n",
      "Epoch 55, Val RMSE: 53121.79\n",
      "Epoch 56, Val RMSE: 53065.57\n",
      "Epoch 57, Val RMSE: 52750.33\n",
      "Epoch 58, Val RMSE: 53361.94\n",
      "Epoch 59, Val RMSE: 53062.28\n",
      "Epoch 60, Val RMSE: 52608.01\n",
      "Epoch 61, Val RMSE: 52634.92\n",
      "Epoch 62, Val RMSE: 52877.28\n",
      "Epoch 63, Val RMSE: 53759.67\n",
      "Epoch 64, Val RMSE: 52981.46\n",
      "Epoch 65, Val RMSE: 52824.61\n",
      "Epoch 66, Val RMSE: 53023.21\n",
      "Epoch 67, Val RMSE: 52603.14\n",
      "Epoch 68, Val RMSE: 52455.71\n",
      "Epoch 69, Val RMSE: 52993.81\n",
      "Epoch 70, Val RMSE: 52911.22\n",
      "Epoch 71, Val RMSE: 52839.06\n",
      "Epoch 72, Val RMSE: 52600.95\n",
      "Epoch 73, Val RMSE: 52639.35\n",
      "Epoch 74, Val RMSE: 52376.86\n",
      "Epoch 75, Val RMSE: 52761.71\n",
      "Epoch 76, Val RMSE: 52602.69\n",
      "Epoch 77, Val RMSE: 52687.24\n",
      "Epoch 78, Val RMSE: 52713.21\n",
      "Epoch 79, Val RMSE: 52383.26\n",
      "Epoch 80, Val RMSE: 52657.54\n",
      "Epoch 81, Val RMSE: 52301.33\n",
      "Epoch 82, Val RMSE: 52580.32\n",
      "Epoch 83, Val RMSE: 53217.36\n",
      "Epoch 84, Val RMSE: 52644.41\n",
      "Epoch 85, Val RMSE: 52994.10\n",
      "Epoch 86, Val RMSE: 52567.37\n",
      "Epoch 87, Val RMSE: 52953.60\n",
      "Epoch 88, Val RMSE: 52710.51\n",
      "Epoch 89, Val RMSE: 52861.69\n",
      "Epoch 90, Val RMSE: 52510.81\n",
      "Epoch 91, Val RMSE: 52275.88\n",
      "Epoch 92, Val RMSE: 53087.13\n",
      "Epoch 93, Val RMSE: 53473.61\n",
      "Epoch 94, Val RMSE: 52187.41\n",
      "Epoch 95, Val RMSE: 51993.89\n",
      "Epoch 96, Val RMSE: 52225.14\n",
      "Epoch 97, Val RMSE: 52265.48\n",
      "Epoch 98, Val RMSE: 53196.87\n",
      "Epoch 99, Val RMSE: 52260.72\n",
      "Epoch 100, Val RMSE: 52065.51\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 100\n",
    "best_rmse = float('inf')\n",
    "patience = 10\n",
    "trigger = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for x_num_batch, x_cat_batch, y_batch in train_loader:\n",
    "        x_num_batch = x_num_batch.to(device)\n",
    "        x_cat_batch = x_cat_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(x_num_batch, x_cat_batch)\n",
    "        loss = criterion(preds, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(X_valid_num_tensor, X_valid_cat_tensor.to(device))\n",
    "        rmse_val = np.sqrt(mean_squared_error(\n",
    "            y_scaler.inverse_transform(y_valid_tensor.cpu().numpy()),\n",
    "            y_scaler.inverse_transform(val_preds.cpu().numpy())\n",
    "        ))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Val RMSE: {rmse_val:.2f}\")\n",
    "\n",
    "    if rmse_val < best_rmse:\n",
    "        best_rmse = rmse_val\n",
    "        best_model_state = model.state_dict()\n",
    "        trigger = 0\n",
    "    else:\n",
    "        trigger += 1\n",
    "        if trigger >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0f6c4cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m     y_test_pred_scaled \u001b[38;5;241m=\u001b[39m model(X_test_num_tensor, X_test_cat_tensor\u001b[38;5;241m.\u001b[39mto(device))\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      5\u001b[0m     y_test_pred \u001b[38;5;241m=\u001b[39m y_scaler\u001b[38;5;241m.\u001b[39minverse_transform(y_test_pred_scaled)\n\u001b[1;32m----> 6\u001b[0m     rmse_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ RMSE test:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rmse_test)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Mario\\FP\\tf_master_env\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Mario\\FP\\tf_master_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:565\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[0;32m    516\u001b[0m \n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;124;03m0.825...\u001b[39;00m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    563\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred, sample_weight, multioutput)\n\u001b[0;32m    564\u001b[0m _, y_true, y_pred, sample_weight, multioutput \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 565\u001b[0m     \u001b[43m_check_reg_targets_with_floating_dtype\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    568\u001b[0m )\n\u001b[0;32m    569\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    570\u001b[0m output_errors \u001b[38;5;241m=\u001b[39m _average((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\Mario\\FP\\tf_master_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:198\u001b[0m, in \u001b[0;36m_check_reg_targets_with_floating_dtype\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, xp)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Ensures that y_true, y_pred, and sample_weight correspond to the same\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03mregression task.\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;124;03m    correct keyword.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m dtype_name \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(y_true, y_pred, sample_weight, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[1;32m--> 198\u001b[0m y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# _check_reg_targets does not accept sample_weight as input.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;66;03m# Convert sample_weight's data type separately to match dtype_name.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Mario\\FP\\tf_master_env\\lib\\site-packages\\sklearn\\metrics\\_regression.py:106\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype, xp)\u001b[0m\n\u001b[0;32m    104\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    105\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 106\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    109\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mreshape(y_true, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Mario\\FP\\tf_master_env\\lib\\site-packages\\sklearn\\utils\\validation.py:1107\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1103\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m   1104\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[1;32m-> 1107\u001b[0m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1108\u001b[0m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[0;32m   1115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[0;32m   1116\u001b[0m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Mario\\FP\\tf_master_env\\lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mario\\FP\\tf_master_env\\lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    167\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    168\u001b[0m     )\n\u001b[1;32m--> 169\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred_scaled = model(X_test_num_tensor, X_test_cat_tensor.to(device)).cpu().numpy()\n",
    "    y_test_pred = y_scaler.inverse_transform(y_test_pred_scaled)\n",
    "    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"✅ RMSE test:\", rmse_test)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.4)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Valor real ($)\")\n",
    "plt.ylabel(\"Predicción ($)\")\n",
    "plt.title(\"Predicción con Embeddings\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_master_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
