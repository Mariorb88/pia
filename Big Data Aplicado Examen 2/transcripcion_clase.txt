 Gracias Manuel. Bueno, pues lo he dicho. Teníamos una nube que esta nube está compuesta de ordenadores, de nodos que nosotros no veíamos, pero que cada uno hacía un trabajo sumado. La idea de HDFS, que voy a poner por aquí, la idea de HDFS es que cuando nosotros subiéramos un archivo, este archivo lo íbamos a mandar a un ordenador principal, en principio su papel no tenía nada que ver con la parte de almacenamiento, era un poco el gestor, y este ordenador lo que va a hacer era dividir el archivo, lo que le mandáramos a él le da igual, lo va a dividir en bloques de 128 megas o de una unidad. Y esos bloques lo se iba a replicar, pues este lo hoy va a mandar aquí y aquí y aquí. En casos que nosotros subimos a ver en HDFS un bloque, pero sabemos que estaba replicar, que estaba copiado en varios ordenadores. Y con este otro bloque, pues si va a hacer exactamente lo mismo, por luego va a mandar también aquí y aquí. Pero nosotros lo que vamos a ver es que esta aquí, nosotros íbamos a ver ante nuestros ojos, esto es el archivo que nosotros habíamos subido, pero sabemos que está dividido en cachos. Esto en principio podía parecer buena idea, pero igual no le veíamos utilidad así la primera vista. Igual después cuando vimos la segunda parte que era el procesamiento distribuido, igual a que tenía un poco más de sentido. Aquí la parte de almacenamiento distribuido la llamamos Jard, que no es directamente un, perdón, masivamente distribuido, no es un gestor de recursos. ¿Qué quiere decir esto? Si nosotros tuvimos que trabajar solo contra un fichero, es difícil trabajar en equipo. Si tenemos que hacer un asumo muy grande, muy grande, muy grande, muy grande, todos alrededor de la suma ya sabemos lo que pasa. Uno está haciendo las cuentas y nosotros apoyamos a la persona que lo esté haciendo. Lo propio sería dividirnos el trabajo. Lo que hace ya es escapar de crear en estos ordenadores que tenemos aquí, lo dibujar en otro color, en estos ordenadores que tenemos aquí, es escapar de crear un contenedor. Esto personovas de datos, pero vamos a pensar que es un contenedor. ¿Y por qué lo crea en estos ordenadores y no en otros? Porque ahora quiere procesar este cacho. Este cacho lo puede procesar en cualquiera de estos ordenadores. Esto ordenador aprovechando que este bloque de aquí ya está físicamente en este ordenador y que este ordenador tiene procesador, ya tenemos aquí todo en este ordenador para poder procesar. A la vez, a la vez, en este otro ordenador de aquí va a crear un contenedor porque esta otra parte del archivo, otro bloque, ya está físicamente aquí y con los procesadores que tenga este ordenador ya se puede computar aquí y aquí a la vez. Esta era la gracia de la distribución. ¿Por qué es esto? Porque cuando los problemas crecen, crecen mucho en escala de Big Data, un ordenador lo puede ir partiendo, lo puede ir troceando. Como cuando le damos la vuelta a la cinta del espectro, no cualquier cosa así. Se puede trocear los datos y un programa, pero es muy lento, muy, muy, muy lento. Un solo ordenador tardaría muchísimo en procesar datos en la escala de Big Data, en cambio si los dividimos, si somos capaces de dividir el procesamiento entre muchos ordenadores, entonces el tiempo baja drásticamente y la ventaja es que al tenerlo ya implementado de esta manera, añadir más ordenadores es muy fácil, estribial. No tendría más que, por ejemplo, aumentar el número de réplicas, si quisiera. El lugar de las tres que tengo por defecto, pues lo digo mira, temporalmente en este archivo le vas a dar réplicas 10, porque quiero tener cada bloque replicado 10 veces para que 10 ordenadores pueden estar a la vez en distintos bloques o en el ordenador. O en cada uno. Entonces, este concepto que tenemos aquí de contenedor que vimos por encima en el primer parcial, aquí ahora dentro unos minutos empezará a tener un poco de sentido, porque este contenedor realmente es una reserva de memoria y de procesadores. Cuánto memoria necesitamos, cuánto procesado necesitamos, porque los datos ya los tenemos aquí en HDFs. Entonces una cosa importante cuando estamos hablando de procesamiento distribuido, que es la clave de este parcial, el procesamiento de los datos tienen que estar aquí en HDFs. Es verdad que nosotros procesamos el cachito local que guarda físicamente su ordenador, pero los datos tienen que estar en HDFs. Si yo me conecto desde mi casa con mi portátil y tengo aquí el dataset que quiero procesar, ya estoy tapando yo mismo. Esto es mi portátil y esto es el dataset que quiero procesar. Ya es una cosa rara porque en escala de big data es un poco raro que los datos entren en tu portátil, pero suponiendo que pudiera ser así, yo no puedo procesarlos directamente antes, tengo que copiar los HDFs que se distribuya entre todos los nodos, una chapuzas de haciendo aquí y una vez ya distribuidos, entonces es cuando lanzo mi programa. Entonces volveremos aquí a los contenedores dentro de un rato, pero en esencia aquí lo dejamos en el primer parcial. Entonces entramos a lo que sería ya el segundo parcial, que es un tema puro, puro de procesamiento distribuido. Al final de la unidad 3 os había dejado varios ejemplos de procesamiento distribuido un poco incremental. La primera que vimos, la primera que vimos es el contador de palabras. El contador de palabras, porque esto es el origen de map, los mapers y los recursos, ya existían en los lenguajes de programación, pero digamos que esta estructura la definió o la usó precisamente Google en sus inicios cuando tenía que hacer el page rank de cada página. Entonces tenía que analizar cada página que recorría para ver cómo de buena era, según los criterios que Google decidiera, que después fue cambiando a lo largo del tiempo. Cuántas veces se repetía una palabra, si tenía título no, si tenía enlace a páginas de referencia, si otras páginas las enlazaban a ella. Todo eso pasaba por recorrer el HTML, del otro módulo, ya sabamos recorrerlo con VToolsup, recorrer el HTML e ir buscando la información esta que nos interesa. ¿Qué pasa? ¿Qué? Google recorría, como la ciencia de manera automática, hay recorrer un montón de webs al día. Entonces esto generaba un volumen muy grande información que un sol ordenador podía procesar lo encolaba y ya terminaría, pero entonces los resultados no estaban rápido. Y Google lo quería rápido, si nosotros hacéis una consulta en Google, sabéis que buscéis lo que buscéis, tardan menos de un segundo. Tenéis los resultados, mejores opciones, pero tenéis los resultados en pantalla. Entonces Google lo que quería era velocidad y de eso surgió el mapre, porque era una manera sencilla de poder procesar de manera distribuida esos logs, esos archivos que iba descargando para puntuar, para valorar cada página. Y esto lo hacía de manera automática. Entonces el primer ejercicio, lo el amundo del mapre, Dios es por tanto un contador de palabras, porque es un poco lo que podía hacer Google en ese momento. Entonces bueno, el primero que os pongo aquí es Java, es Java, porque en principios de los 2000, Java era el lenguaje que lo petaba, estaban todos los dispositivos y quedó un poco heredado de igual, ni mejor ni peor, es el que había, igual que ahora hay Python, ni mejor ni peor, es el que hay, pues, este era el del momento. Como no estamos viendo Java, largo del curso, pues este va a pasar de puntillas, porque sólo una cosa histórica. Nada más, en el manual tenéis como escribirlo y cómo generar el Java, el archivo comprimido donde está en las clases de Java para poder ejecutar. Solo para Java. Después, bueno, después vimos cómo hacerlo en Python, en Python tenía truco, porque más predios, jadup en general, sólo funciona con Java, entonces había que hacer alguna clase de trampa. Y los dejados inventaron jadup streaming, que tiene un nombre muy guay, pero que básicamente lo único que hace es en las fases en las que interviene el usuario, el programador, que es las fases de map y las fases de reduse, esta etapa, la apunta a la terminal, a un dispositivo de entrada está entrada, de salida. Entonces, lo que hace jadup, a través de jadup streaming, es cuando llega el momento de pasar los datos al map, no sabe a quién se los pasa, los envía la terminal esperando que alguien que tú le digas, lo recorra. Ese map, que tú has hecho un Python, lo recorre, va generando parejas de clave valor y las devuelve a la terminal. Y las devuelve a la terminal. Jadup streaming la recupera, hace ahí la fase de software, la ordena, y después se la devuelve a través del terminal para que algo, alguna entidad, un reducer que tú has programado, que les he dicho que de verdad que va a estar ahí para recoger los datos, lo recoja, los trate y los vuelva a emitir a la terminal en forma de resultado de lo que quieras, para ejaclar el valor o lo que tú quieras. Esta es la idea de jadup streaming, muy usado, porque ahora lo que está de moda es Python y otro tipo de lenguajes con lo cual se usa. ¿Qué estamos haciendo realmente? Estamos ejecutando un map de Dios contra un programa Java, que se le jadup streaming, que se encarga de hacer esto. En esta parte de la programación, como está diciendo con el Alejandro Python, es el lenguaje que está en la moda, el próximo año creo que hay incluso no especialización de Python. Como este es el lenguaje que vamos a usar, aquí, preferentemente, vamos a hacer todas las aplicaciones en Python. Durante las actividades que os propuse, lo ideal sería probarlo. Mi preocupación es que alguien no tuviera implementado un cluster en su casa, en sus máquinas virtuales. Yo quería dar una alternativa para que la gente que no tenía equipo suficiente o no había hecho esa parte y quería incorporar esa partida. Aquí hay varias maneras de afrontar el problema. Una de las maneras es crear un cluster jadup de un solo nodo. Esto no es un cluster jadup, esto es una caricatura, un dibujo, porque nada de la potencia que nos ofrece jadup está en un cluster de un solo nodo. Pero tiene una parte buena, que es bastante sencillo de configurar, me parece a mí, segurísimo para los que ya alguna vez implementaron el cluster jadup con varios nodos, pues hacerlo con uno es extraordinariamente sencillo, porque realmente el único parámetro que hay que modificar es de las réplicas. Cuando configuramos hdfs site.xml, había un parámetro que era dfs, y me parece que era que por defecto está 3 y tú no tocas, queda por defecto a 3. Y creo que la práctica lo habíamos bajado a 2 o lo habíamos subido a 5, no lo sé. Bueno, pues en un cluster jadup de un solo nodo no podemos tener cuatro réplicas, si nosotros levantamos eso, jadup le vas a plotar la cabeza, porque va a querer tener cuatro réplicas, en un solo nodo, va a desatar copias de seguridad al oloco, en un mismo nodo, que no sé ni siquiera si se puede. Entonces es muy mala idea. Casi casi el único parámetro que hay que modificar es de las réplicas aún, todo el resto básicamente apunta a localhost. Alguien durante este trimestre me escribió para comentarme que tenía algún problema en... El aparte de crear el cluster este jadup de un solo nodo, lo único que se me ocurre, porque creo que perdimos el contacto, parece que todo fue bien, entonces no volvió a preguntar. De todas las opciones que le di, no se igual funcionó, yo entiendo que la que funcionó fue que, acordaros que el cluster jadup no quiere tratar nada de sistemas, nada de nada, quiere que todo funcionen. Entonces, aunque tú eres un único nodo, un único nodo, para la conexión SSH contratimismo, tienes que pasarte la llave privada también, llave públicas llave privados, ¿sabes? De aquello para no tener que poner contraseña, pues por primera y única y última vez tienes que copiársela a localhost. Entonces te dirá que ya la tiene, te pedirá la contraseña, la pones y entonces desde ese momento ya puedes hacer un SSH a localhost a ti mismo sin necesidad de poner contraseña. Yo creo que este era el paso que faltaba, aunque pueda parecer un poco que no tiene sentido, como jadup está pensado para distribuido y está pensado para todas las conexiones que sean, a través de SSH contra otros equipos, cuando hay un caso excepcional en el que te conectes contratimismo, pues lo tratada igual, como un localhost. Nos ahorramos las DNS y toda la pesca aquella, pero eso se había que cambiar. Entonces, yo, por ejemplo, ya lo voy a lanzar, está all.sh. Este es mi claster jadup de un solo nodo, no tiene nada, tiene una configuración básica, seguir el PDFs y listo. Me arranca el NEMNODE, me arranca los data nodes que es yo mismo también, me arranca un segundo NEMNODE que lo hace por defecto. Y los papeles de JAD también, yo soy todo, yo soy NEMNODE, el data node, el node manager, el de software, yo soy todo porque soy el único equipo que ha hecho. Acordaros que para comprobarlo teníamos un montón de comandos, pero algunos también teníamos la aplicación web. El porto que 9870 era la parte de HDFS, aquí la tenemos funcionando con un único nodo, sin más. Y aquí tenía una pequeña parte de una especie navegador del sistema de ficheros HDFS, que deja por ahí para ver qué va pasando. Si habéis usado este navegador web, habréis visto que funciona mal en el sentido que no te deja hacer nada, porque se supone que hay un usuario que se llama Doctor Who, que es el que gestione estas cosas. Pero en HDFS, que es como un sistema de ficheros Linux, el Doctor Who no tiene permisos, entonces hay que darse los con un CHMOD, que modificar o bien en los parámetros de JAD. Si en lugar de Doctor Who te pones a ti como gestor, como cliente, pero como usuario, como usuario que va a manejar esto. Bueno, esa era una alternativa que os daba, creo que sabéis que tu furo de esta era una opción muy buena, digna también. Y después habéis una opción de juguetes, que era malísima excepto por el tema de purar para que en el programa mal como yo, y no lo veas y todo, y tengo que ir paso por paso, en el fondo está bien. Pues ponerlo todo por comando, sin ningún jado por detrás, es tomar este archivo con una tubería, pasame este Mapper, de este Mapper Ordenamelo, os dí yo el Python para ordenar, incluso podéis utilizar el comando sort de Linux. Y con otra tubería pasáselo a un reducer para que lo haga, el fondo es encadenar comandos y atrás de las tuberías que la salida de uno pasa alanzada del otro. Así como sistema, es una opción relativamente digna y te permite depurar con medianamente facilidad. Es complicado depurar en distribuido, porque tienes que simular un montón de situaciones que no sabes si se va nada. Entonces, esto que usó así, algunas consultas al principio, porque no se sabía si había que hacer un claste grande, en un claste de un nodo, o en tal. Lo podéis hacer en lo que queráis, porque ahora veréis que lo que me importa es la parte de Map y Reduce, que es un Mapper, que es un Reduce, que hace uno, que hace otro, y inventar algunos casos y pensar cómo había que hacer uno y otro para que funcionaran. El lesamen, acordaros que es apapelco, lo cual no hay nada de programar, pero sí hay cosas de programar. Se puede programar pues un poco así en prosa, que va a hacer, que es una nota, para desaprobar, pero es una nota, se puede hacer una especie de pseudo código, que es más nota. Y no espero, no espero, que nadie lo haga en el caso de que nadie lo haga perfecto un Python con sus intentaciones y con todas sus historias, porque es un esamen en papel. Ahí va a estar el límite. Los explicar, estás aprobado, se hacer un pseudo código, bastante digno, pues adelante el fútbol para trabajar. Vamos al entonces. Bueno, antes de poner con el código, que es lo que nos va a llevar más tiempo, voy a pasar muy, muy por encima por esto de mr. Mapper Dios, yo, aunque a todos nos sale a llamar de Mister Job, esto es un código, bueno, es una librería, mr. Yo, es una librería de Python, que te permite implementar en un único Python, en un único programa los Mappers y los radíoses. Entonces, básicamente tenemos que volver a escribir una clase Mapper y una clase radíoses, con lo que sé. Aquí no hacemos un print, en terminal, aquí hacemos un Gid, bueno, es una pequeña diferencia, pero la esencia es la misma. Esto tiene varias ventajas, una, que es muy, muy fácil depurarlo, porque aquí sí que no necesitas ni un cluster jado, ni de muchos nodos, ni de un nodo, ni no, aquí no necesitas nada. Simplemente, 08, 010, no sé, la que sea, y vas depurando, no sale desde Python, después cuando lo quieras lanzar contra un cluster en el momento de lanzarlos y que le tienes que indicar que lo quieres lanzar contra un cluster, pero si no, lo ejecutan lo que. Y lo bueno es que no sale aquí, tiene más ventajas, en algún caso un poco raro que veremos dentro de un ratillo, hay veces que queremos hacer un Mapper, pero no queremos hacer un radio ser, pero el mejor nuestro problema es arreglar solo con Mappers. O a lo mejor queremos hacer un Mapper, un Radio ser y nuevamente otro Radio ser. Bueno, podríamos hacer esto en realidad en jado, no se hace así, se hace un trabajo, es un Mapper y un Radio ser. Si tú necesitas un Mapper y otro Radio ser, en realidad estás haciendo un trabajo con un Mapper y un Radio ser y otro trabajo con un Mapper que no hace nada y un Radio ser. La unidad real que existe es el trabajo en el que hay un Mapper y un Radio ser. Si tú problema necesitas un Mapper y un Radio ser, otra vez un Mapper y otra vez un Radio ser, que quiere recorrer y recorrer, nuevamente los datos, tienes que hacer varios trabajos. Yo sé que esto puede llamar un poco la atención, pero para los estéticos que piensan que esto se puede hacer en una sola pasada, pues te recomendaría que pensaras, por ejemplo, en bases de datos, bases de datos cuando tú haces una consulta en tu cabeza, esto fantástico porque crees que vas de arriba abajo o ni eso, vas a saltos a través de los índices y que resuelve las consultas. Pues sí, hay algunas que se hacen así, pero hay otras consultas que requieren de recorrer varias veces a lo mejor ciertos datos, porque no lo tienes todos. Yo que sé, que tienda tienen más ventas que la media de tiendas, ¿cuáles son las tiendas con las que más ganamos dinero? No con las que más ganamos dinero, sino con si yo gano de media mil euros en cada tienda, ¿cuáles son aquellas que me facturan más de mil euros, mil 1, 1, 2, 3? Pues esto si lo piensas en la base de datos esto requiere varias iteraciones, una para buscar el máximo, en perdón la media, para buscar la media, pues que me lee las ventas de todas las tiendas, y entonces puedo calcular la media y, pues, yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que yo creo que MRYOP también lo voy a saltar muy rápido porque es una curiosidad estaba en el temayo es gracias y de ver ya está. MRYOP fuera vamos entonces con compaito. Bien lo dicho mapre Dios esta es lo principal lo principal de este parcial casi diría del del módulo pero claro esto funciona gracias a que hay un jadub por debajo que hay que saber cómo funciona. que por cierto esto aunque es antiguo esto es siriusando en AWS y en servicios solo dedicado a esto MRYOP el astic mapre Dios MRYOP AMAZ es un claste de jadub privado con sus cosas de Amazon con el java de Amazon con todas las cosas de Amazon pero que la idea es esta tu mandas los datos a un s3 que es el HDFS privado de Amazon tu mandas los datos a un s3 mandas tu mape y tu radio tus trabajos a MR y se ejecuta te cobran por lo tiempo por datos por transferencia. bueno entonces ya sabemos que los datos tienen que estar en un almacenamiento distribuido, llamarlo HDFS, llamarlo s3, llamarlo lo que quieras pero tiene que estar en un almacenamiento distribuido porque lo que queremos es que los bloques estén dispersos para poder atacarlos individualmente. Una vez tenemos los datos en un almacenamiento distribuido se aplican los mapes los mapes tienen como única misión en su vida transformar esos datos en bruto que para nosotros en principio siempre van a ser líneas de texto podrían ser Jason podría ser resultados de una base de datos podría ser pueden ser lo que sea pero para estos ejemplos de aquí yo voy a utilizar líneas del texto pero entender que esto se puede ampliar a lo que quieras, a lo que quieras, imágenes lo que quieras, bueno entonces lo que va a hacer esto va a ser leer los datos en bruto procesados de alguna manera y tal vez no generar ninguno o 23 yo que sé parejas de clave valor, bueno pues no lo sé si estamos al si estamos revisando un dataset de imágenes y queremos ver pues tenemos todas todas las imágenes de todas las matrículas que se capturan en los mercadonas de España, porque se capturan las matrículas las tenemos todas, son un montón de imágenes que hay que procesar muchas muchas imágenes, entonces lo vamos a hacer en un mapper dios, bien pues el mapper al mapper le pasamos la lista de imágenes donde la ruta de las imágenes y el mapper lo que va a hacer es abrir esa imagen y con alguna librería de estas gráficas, óptem, tv o lo que sé, alguna de estas de OCR para interpretar las matrículas, seguro que hay una librería que telematrículas, pero bueno, usa las librerías que tenga cruza para capturar esa matrícula y generar una pareja clave valor en la que ponga pues esta matrícula y y un uno indicando que entrado o a lo mejor en lugar de un uno podemos poner la fecha, un time stamp de la fecha, vamos a poner lo que queramos, de qué detener a esto, de lo que busquemos, pero la esencia del mapper dios es que le hemos pasado, pues si ya tenés este caso una imagen, o en este caso el contador de palabras le hemos pasado una línea y de esa imagen me generó una pareja clave valor matrícula time stamp y en este caso de contador de palabras de una fila que le estoy pasando, me está generando pues 4, 5, 6 las que tenga parejas de clave valor donde me pone la palabra y uno indicando que aparece una vez, cada matrícula es distinto, pero la esencia es que va a coger esos datos y los va a procesar devolviendo parejas de clave valor, en el primer caso ya nunca más vamos a tocar esa imagen, nunca más, y en este caso la línea ya nunca más la vamos a tocar, a partir de ahí, de eso en todo palabras y el otro ya son todos matrículas con el time stamp, entonces primer paso mapper se encarga de los datos y los convierte en pareja, claro, vale, entonces aquí tengo y va a ponerme yo pero aquí lo que busco es un coche con su matrícula, vale, que la línea y de aquí tengo la matrícula y time stampa y la hora, esta es la pareja clave valor que el mapper me daría de esta imagen, vale, pues que el soldado ahí por internet además una URL, este mapper descargaría esta imagen, haría un recués de esta URL, se descargaría la imagen, le pasaría la librería que fuera, le iría la matrícula, si se puede leer la matrícula, me generaría un mapper, si no se puede leer porque yo he veo, porque está nublado, por lo que sé, pues no me genera nada, se nos ha colado un coche, sabemos que pueda haber ruido en los datos, en el otro ejemplo de un archivo de texto muy grande, con muchas líneas, una de estas líneas pasa al mapper, y yo lo que voy a devolver es palabra y un uno indicando que es una aparición, vale, aquí en el valor, y puedo poner lo que me da la gana, te he hecho clave valor, los que ponen a un musiferado de cosas, clave valor, bueno, podría poner un nulos y quiero, podría poner lo que me diga la gana, lo que me diga la gana como lo, siempre que después sepa que en el reducer lo tengo que tratar, en funcientes, que más ejemplos, imagina que el lugar de un archivo de texto es un archivo de lojo, hay unos archivos, después os enseñó una captura, en Apache, por ejemplo en los servidores web, se la ver un lo, para los errores, sin fallar algo que tuvo que decir a ver qué fallo, después hay otro log para los accesos, desde este IP se solicitó esta URL o este archivo, este imagen, este tal y van a fuego para abajo, se una busca de rápidas y por internet, cada registro de esos puede tener unos 10 bytes porque tiene muy poca información, la IP, la fecha y el recurso que te descarga, aunque sea una ruta muy larga, bueno, pero la página de Google, por ejemplo, tiene como, no sé, los cuantos millones de visitas, no sé una barbaridad, 30 mil millones de visitas al día, una barbaridad, pues eso es evidentemente no lo tendrá en un solo servidor, pero si pudiéramos tener, manejar todos los logs de todos los servidores que tiene Google, pues sería un log ya en la escala de Big Data, lo podríamos procesar con un ordenador, pero no estarían los datos, mi pao y mi pa mañana, porque ya sabéis, habéis probado que los excel tienen un top de par de gilas, ya con un gilas es fácil que al mover se te cuelen, entonces, ya estaríamos en la escala de Big Data, bueno pues aquí en el log podíamos, yo que sé, IP y cuantas, cuántos maíz se ha descargado, no sé, pues por cada registro en el archivo es, se también te pone el tamaño del recurso que te descargas, bueno, o las apariciones, lo que sea, entonces en función del problema, este MAPER te va a hacer parejas de clave, bien, siguiente fase, Saffel and Shot, aquí la gracia está en que si tenemos muchos MAPER, si tenemos muchos MAPER, porque tenemos muchos datos y se están procesando en Distribuido, vamos a tener un montón de parejas valor, pues está IP, está misma IP, la que sea, la 120 y la que sea, me pueda aparecer en un MAPER, me pueda aparecer en otro MAPER, me pueda aparecer en otro MAPER, en nodos, en nodos HDFS que estaban por ahí distintos, pues en este servidor, está IP dentro ayer, después en este otro servidor, en este otro servidor volviendo a traer hoy, lo que fuera, pero pueda aparecer en distintos MAPER, entonces, la función que tiene este etapa de la que se encarga jado, nosotros no tenemos que hacer nada, es que va a generar las va a unir todas, las va a unir todas en un bloque, digamos, en un bloque, que ese bloque se va a guardar en HDFS, ese bloque va a tener en HDFS, pero tiene la ventaja de que todas esas IPs que estaban distribuidas por ahí, por todo ese dataset inmenso, ahora ya están agrupadas en un bloque o más, están agrupadas, aquí no se te va a colar otra IP, una IP distinta, una IP roja aquí, no se va a colar, están todas las IPs ordenadas, ¿cuál es la ventaja de eso? Que después cuando llega el reducer y le pasas este bloque, él sabe que todas esas IPs están seguidas, están juntas, si tú estás revisando un IP, pongo, pongo, pongo, en el reducer y llega otra IP, tú ya sabes seguro que esas IPs de antes ya acabaron, ya no hay más, no te va a volver ninguna otra más, ya están finalizadas, te vuelvo a otra IP de otro equipo, esto que de entender es sencillo, después de aplicar, cuesta un poco más, hay que cambiar un poco la mente y adaptarse a este procedimiento, así es como se trabajan en distribuido. Si nosotros tuvieramos que hacer una suma muy grande, nos la tuvieramos que repartir, habría un poco de trabajo burocrático que tendríamos que hacer, yo haría mi parte de la suma y te tendría que indicar, oye, y me llevo una, acuérdate que me llevo una, tú harías tu parte de tu suma y a lo mejor no te llevas una, otra haría su parte de la suma y a lo mejor lleva dos, yo que sé, pues en una segunda vuelta alguien tendría que juntar esos resultados, en una suma da igual, pero si hubiera suma multiplicación de visión que sabéis que hay hay una prioridad en cómo se aplican las operaciones, pues ahí el reducer sí que tendría que tomar control de las cosas, vale, se puede complicar un poco. Entonces este mape. Para que veáis la estructura, porque en esencia siempre es igual. Tenemos aquí una línea especial que podéis encontrar en muchos scripts, sobre todo de Python, que es una línea especial, empieza como por un comentario que le dice al sistema operativo, cómo tiene que lanzar este programa, porque el sistema operativo no sabe si es tu Python o si es un nuevo lenguaje, pero no lo sabe. Para el texto sin más, entonces con esta línea, el dice, tengo que utilizar este programa el Python 3 para interpretar el resto de las chicas. Bueno, nada, tenemos un import aquí del sistema porque utilizamos, sí, este de Inglemos de la entrada. Temos como si el declaro por el que nos está escribiendo Hadoop en la terminal, lo estamos leyendo allí. Bien, hacemos un, esto es casi padre en nuestro, hacemos un strip para eliminar los intros del final, los espacios que pueda ver al principio al final, y otra cosa que solemos hacer, depender el programa, es un split para partir esa cadena en función de algo que esté buscando, si no pones nada, como en este caso, estás buscando los espacios en blanco, pero podíamos buscar separadores, como hicimos en Power BI, de Puntikoma, nos vendría muy bien para procesar un Csw, por ejemplo, y cualquier cosa que se ocura. Bien, el split nos devuelve una Rai y por último, en este caso recorremos el Rai, que es muy sencillo recorrerlo en Python porque simplemente lo ponemos aquí y una variable temporal donde se va a ir poniendo cada elemento, y lo único que hacemos en este Mapper, tan sencillo, es que en primer, en la terminal, la palabra, ponemos un tabulador por separar, pero podríamos poner un guion o jod, para que no se lie con la palabra, pero podríamos poner aquí en dos puntos, lo que nosotros quisiera, el reducer sepa separar, entienda que es lo que estamos separando, y ponemos un 1, porque es lo típico, aparece la palabra una vez, si después vuelvo a aparecer, aparece otra vez, y si después vuelvo a aparecer, aparece otra vez, será el reducer el que las cuinte, y el lugar de llevar un contador 1, 2, 3, 4, 5, pues a lo mejor ya podríamos aprovechar ese valor para ir sumándolo, si no utilizamos este valor para ir sumándolo, aquí podríamos meter perfectamente un null, que no nos va ni nos viene, porque después vamos a tener en el reducer un contador aparte. Bueno, toda este Mapper, que es muy sencillo, le las líneas, la rompe en palabras y por cada palabra imprime la palabra y un muy muy sencillo. Vamos con el reducer, en este caso el reducer es es un poco más complicado, aquí no porque lo vemos si nos parece trivial, pero pero vamos a pensarlo, porque tendremos que pensar en Mapper sin reduces, la gracia de este módulo será salir de aquí, que no solo sabiendo lo que es, sino siendo capaz incluso de, bueno, pues decir esto lo hace el Mapper, esto lo hace el reducer, como tiene que hacer, yo programo muy mal, porque yo suyo de sistemas, entonces programo muy mal, pero de puro muy bien, entonces creo que es importante coger la servilleta, hacer un dibujo y esto también me ayuda muchísimo dibujar las cosas para verla, todos nuestros bisabuelos y tatarabuelos no eran arquitectos, pero en capaces de levantar una casa de dos pisos en la aldea con ayuda de los vecinos, entonces cosas pequeñas, todos somos capaces de hacerla, pero yo imagino que si alguna ve muchos ois desarrolladores y seguro que habéis llegado algún momento en lo que estáis desarrollando algo y os te discuentro que lo mejor no hiciste un buen diseño y estáis llegando un punto en el que empieza a ver conflictos con decisiones que tomaste anteriormente y tienes que empezar a hacer chapuzadas, no, no sé si me habéis vivido, si vosotros no habéis vivido yo tampoco, pero dicen por ahí que se suele dar, entonces está bien pensar un poco antes como pueden ser los casos que se puedan dar y hacer un pequeño diseño, entonces tengo aquí, me trajo una chuletilla, para ver como haríamos un reducer de 0, este como tenéis el código, lo podemos seguir tanto por código como por diseño, entonces siempre vamos a tener, siempre vamos a tener una primera, un primer bucle, en el que nos preguntamos si hay más líneas, lo estamos viendo, yo soy con el escuel, esto lo rombos era un YF, un seguro código muy cútero, hay más líneas, esto es el bucle que tenemos al principio, que estás esperando por cada línea, bueno lo normal es que si tengamos más líneas, entonces cuando tenemos una línea, lo primero que tenemos que hacer es obtener la clave, de alguna manera aquí en las líneas pues habría que hacer el strip para quitar los espacios y después el split para obtener la letra, cuando perdón la palabra y cuando ya tenemos esa palabra hay que hacer cosas con ella, entonces aquí obtenemos realmente la clave, lo pongo así con un cuadrado porque esto indica que a lo mejor es un método, una función o a lo mejor es una línea sencilla pero que básicamente lo que tenemos que conseguir es una clave, que va a ser nuestra clave de la pareja clave, vale una vez tenemos la clave, estamos en el reducer, estamos en el reducer, nos llega, perdón, perdón que estaba en el mapa, pero con la cabeza, estamos en el reducer, al reducer le llegan las parejas de clave valor ordenadas, le van a llegar todas las palabras iguales seguidas, después otra palabra también las iguales seguida, después otra palabra con sus iguales seguida, van a ir todas las ordenadas, el texto original ya no se va a aparecer en nada, se van a juntar todas las que empiezan por A, todas las que empiezan por B, como si fueron diccionarios, vale, entonces yo ahora que estoy programando el reducer, voy a leer y me van a llegar las parejas de clave valor ordenadas, leo la clave, bien, si yo lo que quiero tener es cuántas veces aparece cada palabra, necesito un contador de alguna manera, tengo que contar esa clave, me ha parecido a nabés, tengo que actualizar ese contador, lo voy a actualizar siempre, siempre que me ha parecido esa clave, pero me va a aparecer esa clave siempre, en algún momento no me aparecerá y como distingues si me aparece o no me aparece, bueno pues la única más nueva para extinguir si la clave que te acaba de llegar es distinta del anterior pues es precisamente esa, tener en algún sitio un anterior, un anterior, la variable anterior es una cosa provisional para en el proceso de la clave actual saber si hay que sumársela o no, entonces el anterior va a funcionar siempre bien excepto en la primera iteración porque anterior cuánto vale, cuánto vale anterior en la primera iteración, es complicado, entonces lo vamos a hacer es meter una variable por aquí una de la que es non es un caso especial, vale, entonces aquí comprebo, si anterior es igual a non si es igual es que estoy en el primer caso, que esta variable está como sin actualizar, este en el primer caso, entonces excepcionalmente en este caso y solo esta vez lo que voy a hacer va a ser que anterior se igual a la clave, esto es una trampa que estoy haciendo en el primer caso como si ya te conociera, entonces la primera pero sí, es igual al anterior virtual, bueno y en el resto de los casos como anterior ya va a tener valor, esto ya me lo voy a saltar, este condición de aquí solo se va a ejecutar es una cosa especial que solo funciona cuando llega la primera línea, cuando llega la primera pareja clave van a haber, bueno ahora sí empieza un poco lo que es el tratamiento, si la clave es igual a la anterior, si la clave es igual a la clave cubiera anteriormente, si es que sí, entonces tenemos que contar uno más, tenemos que contarlo no más, tenemos que contarlo más, tenemos por aquí un contador 0 y aquí le metemos un contador más más, se entiende, vamos a poner por ejemplo un caso, me llega a 1, me llega a 1, la palabra ha parecido una vez en el máper, esta es la primera pareja clave valor que me llega, entonces vengo por aquí, consigue la clave, voy a poner otra por aquí, clave, la misma clave es la, consigue la clave y tengo aquí anterior, ahora mismo es non, tengo el contador, ahora mismo es 0, ahora mismo es 0, bueno entonces ya tengo la clave que esa, anterior es igual a no, anterior, si es igual a no, entonces no vengo por aquí y el anterior es la clave, voy a decir aquí, que chamosa, la clave la voy a poner por aquí y el contador sigue siendo 0, vale, y vuelvo por aquí, entonces esta es la excepción que hice para la primera vez, me vengo aquí, la clave es igual a la anterior, la clave es igual a la anterior, si, entonces aumento el contador, contador que aquí tiene 0, ahora tiene 1, ahora va la cosa bien, bueno en esta iteración ya no tengo nada más que hacer, ya es la 1, ya ha entrado, no tengo nada más que hacer, con lo cual, con lo cual me vuelvo al bucle, y espero hasta que llegue otra pareja clave valor me van a llegar todas seguidas, vamos a suponer que llega otra vez a 1, porque la palabra ha aparecido más veces en el texto y como el software lanzor, la has agrupado, ahora me van a venir todas contas, vale, pues sigo recorrendo, consigo la clave, que es a, anterior es igual a no, no, anterior no es igual a no, entonces me vengo por aquí, la clave es igual a la anterior, la clave es igual a, a, pues sí, es igual a, entonces me vengo por aquí, aumento el contador, vamos a morrerno, aumento el contador y por ahora va la cosa bien, tendría el resultado sería a 2 veces ha parecido, que es justo los datos que tengo, voy a hacer una vez más, éticos, vuelvo aquí, consigo la clave que es a, esta parte del bucle, ya nunca más, sé que nunca más la voy a ejecutar, porque nunca más anterior va a ser no, esto solo era al principio del programa, vale, una chaposa que tuve que hacer, pero es un caso excepcional el primero que que gestiona, vale, la clave es igual al anterior, pues sí, la clave es igual al anterior, sumo uno más, igual a algunos, os estoy aburriendo, porque esto es muy sencillo, pero es una manera de pensar que después te ayuda, vale, y podríamos seguir así un montón de tiempo, pero ahora resulta que nos llega otra palabra, todas las as, ya las hemos procesado y ahora nos llega otra, lo que sabemos seguros que ya nunca más nos va a llegar una, porque más predíos las ha juntado todas, la fase de esa desafen las ha juntado todas, entonces si esto nos simplifica mucho los medios, porque ya no nos tenemos que preocupar de sumarle a añadir el contador a la A, vale, se des cuenta de la ventaja que esto supone, esa fase de desafelando de dios, aunque es tremendamente lenta, porque requiere proceso y guardarlo en un HDFS, es tremendamente lenta, pero a la hora de hacer el rey user nos libera de un montón de problemas, porque esta clave ya no vuelva a aparecer, yo ya me desentiendo, bueno entonces me llega la vez, vengo por aquí, consigo la clave, ahora la clave, ya no es a, ahora la clave es B, este cachamarillo ya me lo salto porque nunca más anterior vuelva a ser a no, anterior es la A y me vengo por aquí, la clave es igual al anterior, pues en este caso no, la clave, ya no es igual al anterior, ya no lo su, no, que es lo que tengo que hacer ahora, pues realmente este dato ya lo puedo mandar, ya podría mandar un A3, esto es lo que me gustaría que el rey user mandara, no, tengo esos datos, pues sí tengo el A aquí y tengo el 3 aquí, pues listo, vent, anterior, puntador, eso es lo primero que hago, no puedo volver arriba, porque si volviera arriba perdería, habría perdido esta vez, realmente no la habría tratado, entonces además de hacer el print para que me saque este resultado, ya tengo que gestionar aquí mismo la vez, entonces aquí es cuando hago que la anterior, ahora mismo es la clave, no, la anterior, ahora mismo es la clave, esta en aquí, la vevo, y el contador, a cuánto lo ponemos, que dice al poner la cero, no, da una ganas de poner a cero, pero no lo ponemos a cero, porque esta cuenta, está cuenta, el contador es uno, porque la estoy procesando, digamos que esto es la parte de procesar la primera vez esta vez, es cargouste 3, o muy muy, bueno, ya me pongo más, entonces me vuelvo hasta otra iteración, bueno, me vuelvo a llegar otra vez, pues aquí la idea es la misma, me vengo aquí, consiguo la clave, que es ve, esto amarillo ya mi lo veo, la clave es igual al anterior, la clave está es igual al anterior, sí, entonces me voy por esta rama que sumo uno, sumo uno al contador, decirme eso es aburro mucho, que pasamos a otro, y vuelvo para arriba, perfecto, último caso, venga, cambiamos, me llega a un acé, yo ya sé que no me van a llegar más ais, yo ya sé que no me van a llegar más vez, y ya está, por ahora es eso lo que sé, me llego un acé, me vengo por aquí, ya consiguo la c, ya consiguo la c, no lo estoy amarillo, la clave es igual al anterior, sí, es igual a b, no, entonces me vengo por aquí, imprimo el anterior y el contador, imprimo el anterior, que es la b y el contador, que me viene perfecto, que es justo lo que quiero devolver, y al anterior, le dé el valor de la clave, al anterior, le dé el valor de la clave, y el contador le pongo uno, le pongo uno, porque es, porque es esta iteración, bueno, podríamos seguir así, mucho tiempo, mucho tiempo, pero en algún momento ese map era acaba, ese map, porque ya le ha mandado todo lo que tenía, porque se ha acabado ese bloque de datos de HSS y tiene que pasar a otro, en algún momento ya no hay más líneas para recibir, entonces es la última línea, pongamos que esta, esta c1 es la última línea que nos llega, pues le hemos procesado, si, la hemos procesado, estamos aquí, volvemos aquí, hay más líneas, no, si yo acabara el programa ahora, si este no que me sale del bucle, me acababa el programa, yo habría devuelto este resultado, que está bien, habría devuelto este resultado que está bien, pero me ha faltado de volver el último, el que fuera, el que fuera, me da igual que tuviera solo una aparición o que tuviera 25, en el último bucle, aunque si fuera un contador, si fuera la misma clave, sería un contador y llegaría aquí, y ya no llegaría más, y si es otro lo contaría, pero no lo habría impreso nunca, no, no se que por aquí, no hacemos nada, entonces siempre nos va a quedar una bala en la recámara que tenemos que imprimir, por suerte tenemos todos los datos, tenemos la clave y tenemos el contador, lo cual, la clave y el contador, y aquí ya sí, vale, es un poco lido, es un poco lido, pero conviene hacer unos ejemplitos, unos casos, el caso genérico va a ser fácil, básicamente el caso genérico es este que tengo aquí, sí es igual que el anterior suma 1, y si no es que ha cambiado, me imprime ya el resultado que tengo calculado y volvemos a empezar de hacer, esto sería el caso principal y después nos van apareciendo cosas, de otra, el último no se imprime, pues hay que gestionarlo, y el primero íbamos a tener problemas también, pues hay que gestionarlo, el primero, el último y el caso genera, esto tiene una forma poco rara, bueno, pues esto, de primero de programación de 1995, se traduce en esto, tenemos aquí las dos variables que inicializamos, porque nos hacían falta, después teníamos aquí el hay más líneas, que sería este, mientras haya más líneas, lo que sea, esta toda esta parte es para conseguir la clave, aquí me llegaban parejas de clave valor, la hago el strip por defecto, para, después de puráis, veis el barra N del final, que no puede causar problemas y tal, entonces el strip hay que hacerlo casi sin pensar, después hacemos un strip, pero no buscamos espacios en blanco, en este caso buscamos tabuladores, que ya se lo meten en el map, vale, el map y reduce, tienen que ser amigos, tienen que comunicarse, después pasar lo que quieras, pero tienen que ir poco de la mano, y sé que es una pareja clave valor, está dividida por un tabulador, con lo cual cuando le hago el split, lista, es una raik, que va a tener dos posiciones, dos elementos, vale, yo esto lo sé, porque sé seguro que al reduce le van a llegar parejas de clave valor, lo parto por la mitad, pues uno es la clave, y el otro es el valor seguro, me quedo solo con la clave, con el que está en la posición cero, vale, es el único que me interesa en este caso, el valor no me interesa, bueno pues uno, lo podría aprovechar lo que bueno, yo ya sé que es uno en este caso, aquí tengo el texto comentado, las apariciones es la otra posición que está ignorando de la lista, la pareja clave valor que me partió, pues la otra, y también lo podría haber hecho así, la clave y el valor ya directamente con el split, lo puedes hacer de muchas maneras, aquí viene el elifeste que habíamos puesto al principio, si la palabra anterior es no, este es un caso especial que solo va a aparecer en la primera iteración, entonces hacemos el truco este, provisionalmente la palabra anterior es esta que estamos tratando, y después hacemos el caso general, que es este, que si la palabra que tenemos ahora, la clave que tenemos ahora, es la misma que está mostratando hasta hace un momento, la iteración anterior, entonces realmente en esta etapa de reduce solo vamos a contar una más, pues le metemos el contador más uno, no hace falta coger el valor de aquí, y si ha cambiado si la clave no es la misma que la que tenemos anteriormente, entonces lo imprimimos con los valores que ya tenemos y hacemos la jugadita, ojo aquí con el contador uno, porque aquí tenemos un contador cero que nos resulta todo natural, y aquí tenemos un contador uno que igual no nos resulta natural, hay que saber de dónde viene, y cuando acaba el for, cuando acaba el for siempre nos va a quedar una bala en la recámara, siempre no, siempre no, estoy pensando ahora, un mape que no generara ninguna pareja clave valor, pues igual no generaba bloque, igual no llegaba ningún reducirse, no lo sé, tendría que ver, pero bueno se podría gestionar también, vale, en principio suponemos que nos queda siempre una bala en la recámara, pues hay que imprimirla, es el código que teníamos después, vale, bueno, cómo lanzábamos esto, cómo lanzábamos esto, esto lo lanzábamos, tenemos que hacer lo siguiente, primero, primera fase que se nos va a olvidar es copiar los datos a hfs, esto es la primera fase, yo no sé si están, creo que no, tengo aquí una carpeta entrada, que tiene los bluetooth, bueno podríamos hacer los bluetooth, pero voy a pasar, vamos con los bluetooth, pero si quisiera pasar otra cosa, yo creo que tengo datos, si quisiera pasar datos, acordaros, será hfs, dfs y después como un parámetro es cerrado con un dió, el comando Linux es una buena trucos para memorizarlo, que no subirá, hecho lo que quisiera, vamos, vale, un ls, un copiar, un mover, un no sé cuánto, para mover los datos entre local y hfs tenemos otras alternativas, pot, más sencillas, damos la ruta local, que en este caso es idioma.txt y después damos la ruta hfs, ojo porque la ruta hfs hay que ponerla entera, aquí no funciona el tabulador, porque el hfs está en otro lado, no funciona el tabulador, entonces hay que poner la ruta desde la raíz, vale, si no pones la ruta desde la raíz, en los activos de configuración está puesto que tu usuario, el usuario con el que está centrado, supongo que sea la javi, dentro de hfs se va a tener una carpeta personal, como el Linux y el Windows, el Home, entonces si tú pones aquí entrada, esto te va a crear una carpeta javi barra entrada, una carpeta personal javi o Home javi no recuerda con tus cosas, nosotros no queremos carpetas personal, yo no quiero carpetar personal, entonces ya directamente lo voy a poner en la raíz, como Linux, rutas absolutas que empiezan por la barra, empiezan por la raíz o rutas relativas que empiezan dependiendo de dónde estás, vale pues nada, llegamos y si todo va bien, si todo va bien, lo dizamos aquí y ahí tenemos nuestro archivo de datos, bueno, como es esto, contados de palabras, Python que era, bueno pues aquí tengo el map del retiuser y una cheletilla para el caso de emergencia, si, si me olvidado, cómo lanzamos esto, ya tengo el mi cluster de ejecución, mi jadup de un solo nodo de ejecución, entonces para lanzar esto utilizamos, ya en algunos lados veréis que también jadup, o sea podemos utilizar comandos muy concretos como, como este, HDFS, de FS, YAR, y lo que voy a escribir ahora, podemos usar comandos muy genéricos como jadup y ya él entiende si va por la parte de HDFS o por la parte de YAR, yo prefiero ponerlos así concretos, YAR, vamos a ejecutar un JAR, Java, como ya hicimos en el contador de palabras y en el que más cosas había, de palabras, en los ejemplos que venían con jadup, y la ruta de él ejecutable Java que vamos a lanzar, qué ejecutable Java vamos a lanzar, jadup streaming, esto es lo la chicha, yo lo tengo en JADUP mier, El programa que vamos a hacer, este programa pide un montón de parámetros. Yo creo que los puedo poner conozco para que se vean. Un poco la barra esta invertida, me permite hacer un intro sin ejecutar el comando. Tengo que poner aquí un montón de parámetros. El primer parámetro que tengo que poner, creo que era igual el orden, vale. Por sentido, el primer parámetro que tengo a tu paner es input en el que le decimos a nuestro programa donde están los datos. Tiene que estar en hdfs y con lo cual la ruta que pongamos aquí en input tiene que ser de hdfs no vale de dos puntos barra ni home, usuario de local. No es local, esto es pecado, no se puede usar input, nada que no esté distribuido. Esto va a ser una ruta de hdfs. Entrada todo, me procesa los bluetooth y el paquete idiomas. Si no le pongo nada, me procesa todo lo que pueda leer de esa carpeta, sino le puedo poner barra idioma tequistecro. Lo jasíntense. Ahí van a estar los datos de entrada. Lo voy a poner ya, por ejemplo, donde están, donde quiero que me deje los datos de salida. Los datos de salida también van a estar en hdfs. Los va a dejar ahí por defecto entonces, no hace falta crear la carpeta en nada, sin carga él. Salida, salida, salida, le he comprado. Ya le digo en qué carpetas están los datos, le puede decir el archivo concreto que quiero o todos los archivos que están en esa carpeta. Y en auto le digo dónde me va a dejar los resultados de los radíos, se ha acordado que por cada radíuser me va a dejar un archivo. Aquí como solo tengo un radíuser porque solo tengo un nodo, solo al archivo. Pero en el césga me salían 49 radíos después los juntos no son los archivos. Ya tengo la entrada, ya tengo la salida, vamos con el mapa, que es la primera fase. Entonces le digo que como map me tiene que utilizar un archivo que se llama map.py. Esta ruta sí que es local. Es una ruta local. Yo como ya estoy en esa carpeta, ya le pongo la ruta sí. Si estoy en otra carpeta tendría que ponerle bien la ruta. Barra, Home, Barra, Javi, Barra, Programas, Barra, Python, Barra, lo que fuera. Ya queda ser. Bien, este es el programa que va a ejecutar cada contenedor. Cada contenedor. Pero acordaros que los contenedores están dispersos por ahí por el clas... Entonces hay que mandar el archivo del map a ese contenedor. Eso se hace con el parámetro file. Y aquí, nuevamente, le envío el map. Con estas dos líneas, lo estoy diciendo mira, toma este archivo que te envío al contenedor. Cuando crees el contenedor, le copias también dentro de ese contenedor. Este archivo map. Quede además te digo que es el que tienes que lanzar de primero de map. El map y el reducir, lo mismo. ¿Qué voy a utilizar como reducir? Es un archivo que se llama www.reducer.py, poco original con los nombres. Y también te lo voy a enviar. www.reducer.py Vale, creo que no me queda nada. ¿Dónde están los datos? ¿Dónde tiene que dejar los resultados? ¿Qué archivo tiene que lanzar como map y se lo paso? ¿Qué archivo tiene que lanzar como reducir y se lo paso? Yo pienso que está todo. Leamos a intro. Para el nuestro. Si falla, falla aquí. Y es el valor mapper, con lo cual podríamos apostar que tenemos mal el código en el reducir o en esencia está tú. Todos estos datos es que está todo bien. Pero la clave va a estar en. Es salida contador y aquí tenemos un archivo vacío que nos dice que acabó la cosa bien. Y un archivo Part 0000, lo que sea, 01, 02, 02, 02, 03. un archivo part 0000, lo que sea, 001, 002, 003, tantos como reduces haya. No me lo descarajo de eso, en lo principio. Pues, disposición con la comilla está aquí una vez. Entonces, estos almollas con acceso una vez. Y bueno, algunos valores varias veces. No me interesa este resultado con esto. Pues así es como lanzamos los mapre dios. No tiene en principio mucho misterio. Ahora es donde viene la chica. Vamos a abrir varios melones por partes. El primero que me interesa. ¿Qué pasaría si yo en el mape o en el reducer necesito hacer curso de una librería muy específica? Ya no digo pandas, que lo mejor es lo que está instalado en todos los nodos. No, pero aquí hay una celetía. Entonces, nos imaginamos que tenemos un nodo aquí, otro nodo aquí, otro nodo aquí. Y que tenemos los datos en HDFS. Vale, estos son nodos que forman parte de un cluster HDFS. Bien, por resulta que mi maper. Y hace falta una librería X. Es una librería X que no está instalada en ninguno de estos programas. Entonces, cuando yo le pase el archivo Python, cuando yo le pase el archivo Python, aquí se va a crear un contenedor, me acordar un contenedor que va a tener su memoria, va a tener su tiempo el procesador, va a estar linkado al bloque de datos, que ya va a estar en ese nodo. Y ya lo va a tener allí a mano. El input entrada, es donde están los datos. Este input entrada que le pasamos en la ejecución del programa, ya hace que este contenedor tenga los datos de HDFS. El output, salida, también lo va a crear en HDFS y ya no es problema nuestro vale, al mejor, al crear lo crea otro nodo en el mismo donde ya no es problema nuestro HDFS. Y aquí venía la chicha. Estamos diciendo que como MAPER, a.py, como MAPER utilice a.py que es este archivo, y se lo vamos a mandar. Entonces, cuando Jadupe streaming carga, coge este archivo y lo copia en este contenedor y aquí en este otro contenedor que también está distribuido, también lo copia. Esto es como lo hacemos antes, con el reducer lo mismo. El reducer puede estar en otros nodos, porque estos MAPER van a dejar los datos en HDFS y en HDFS los bloque se pueden repartir en otros nodos. Vamos a quedarnos con el caso del MAPER. ¿Qué pasa si en el MAPER necesito pandas y pandas no está instalado en aquí y aquí? ¿Qué hago? Pues una opción es ir con mi cara y ir al administrador del Cresti, es decir, instalabe pandas en todos los nodos. Pero después viene otro colega y dice, pues yo quiero un pensé, y después viene otro, y yo quiero no sé qué, yo quiero no sé cuánto. Y ya no sé si con Alejandro con las herramientas que habéis visto, ya habéis tenido algún conflicto con librerías. Vale, yo el último que tuve es con NumPy, aunque no lo usaba, porque pandas quería una docienda en NumPy y otro librería usaba en NumPy directamente pero con otra versión y se me dio así un poco la cosa. Bueno, pues hay una manera sencilla para pasar para que tus programas pueden usar cualquier tipo de librería, cualquier tipo de librería independientemente de si está en los nodos o no. Vale, entonces una parte importante. ¿Cómo lo hacemos? Pues tenemos que volver al principio del curso donde Alejandro os explicó que eran los entornos, en biómento, no sé, entornos, creo que era entornos de Python. Los entornos de Python son unas carpetas ocultas realmente, unas carpetas donde se guarda allí la versión de Python que tú quieras, la librería de Python que necesites, las cosas que tú quieras, se guardan allí, no se guardan en la carpeta del sistema para que estén accesibles a todo el mundo. Se guardan en la carpeta del proyecto para que solesten accesibles a los de ese proyecto. En tu sistema operativo siempre va a mandar lo lo principal, entonces hace falta un sistema para que tu entorno mande por encima del sistema operativo. Y eso es lo que gestiona el WM de Python o conla, por ejemplo, otra alternativa. Tenemos que activar esos entornos. Entonces cuando activamos esos entornos y ejecutamos nuestro programa, manda más el entorno que la variable local que haya en ese sistema. ¿Cuál es la ventaja que yo me descargo ese proyecto, activo ese entorno y sé que me funciona seguro, independientemente de la configuración que tenga en mi ordenador? Yo creo que ya lo habéis probado con Alejandro, pero ahora es cuando tiene mucho más sentido, porque yo ahora puedo coger esa carpeta y comprimirla. Para no olvidar todos los ficheros, porque son cientos y cientos de ficheros. Entonces lo comprimo, lo comprimo, le pongo yo que se entorno, entorno, sí, o targe, o lo que sea. Un comprimido y lo envío. Y con otro faim lo envío. Además de enviar este archivo a los contemedores, también se va a enviar el entorno, que no sé cómo dibujar lo que ebujar una bola. ¿Cómo se fuera así? La porgüja. Se sube el entorno, el entorno comprimido. ¿Sí? ¿Qué pasa el entorno comprimido? Cuando llegue al nodo, el contenedor va a pensar que es un archivo comprimido y no sabes si es un dataset o unas constantes o no tiene ni idea de lo que es. Entonces, hay que hacer un truquito. Hay que hacer un script. Un script Python en el lenguaje que quieras, que lo que haga sea ver si ya existe esa carpeta y si no existe, descomprimirla y activarla. Estamos haciendo es activar el entorno. Entonces, ahora el mapper ya no va a ser este. Ahora el mapper ya no va a ser este. Ahora el mapper va a ser el script.py. Que primero, activa el entorno compré basistas y no está, pero activa el entorno. Y después lanza mapper.py. Vale, veis la jugada. Darme un poco de feedback. Así en el chato, algo, porque es un poco curioso. Es un poco curioso, pero es necesario. Ahí estamos. Perfecto, perfecto, perfecto. Vamos. Vale, entonces, esta pregunta clarísima de Samen, lo que hace es responder a la necesidad de los usuarios que quieran lanzar un mapper dios a Amazon, el MRS de AWS, que no se tengan que preocupar de si Amazon tiene instalado pandas o una versión de pandas o TensorFlow o PenceU, o lo que os dé la gana. Nosotros en vuestro equipo. En el entorno, instalais, compir, instala lo con la instala, lo que os dé la gana, lo que necesiteis, y llegado el momento de subirlo, lo comprimís y lo tenéis que añadir al entorno. Es un Python, un Python, un Python, solo, lo mejor se pone los yo que es 150 megas. Es bastante teniendo un cuenta que un contenedor es Chiquitin, y la unidad por defecto, yo no sé si eran 512. Esto se puede configurar. Si yo resulta que tengo un entorno brutal, porque tengo 300 mil librerías, tengo que ir allá, que es el que hace los contenedores, y el lugar un contenedor tan Chiquitin, pues igual necesito un contenedor más grande, porque tengo librerías más potentes, pero la idea es esa. Os recomiendo mucho mucho que apuntéis por ahí, preguntarle a Chag GTT, ¿cómo subir un entorno a Map Redduse? Porque os pone los plancha al código de este escrito. Es un bucle, existe esta carpeta, no, descomprime esto, tar menos X, se vuelve VF, este archivo, descomprime lo y condactive it. Y por último, eso sí, lanzar el mapper, desde el script, porque aquí ya no lo vamos a hacer, aquí estamos haciendo una trampa, y decirle al mapper, que primero hago una cosa y después lanza el mapper. Pero está bien para dividir. Sería exactamente lo mismo con el reducer. Al mejor el reducer no necesitan nada más que Python, y Python, sabemos que está instalado en los nodos, pues entonces el reducer sería reducer, como si llaman, reducer y se rompíamos, y ya está, y no lo veis, pero bueno, pues el reducer, el nombre del archivo y fail, el nombre del archivo. No sería nada, que el reducer también usa librerías que no sabemos si están en los nodos, pues lo mismo, hacemos un script para el reducer, que los dos lo hacen, pues lo mismo para los dos. Entonces, podemos enviar aquí al contenedor un montón de archivos, no solo mapper, reducer, sino el entorno, incluso imágenes de prueba o lo que nos dé la gana. De hecho, en las últimas versiones, ya se ponen nervioso, porque no le gusta el parametro fail, prefiere fail en plural, en el que ya le pasas todas las cosas así separado por coma, y ya te las envían todo junto. Entonces eso era, es importante, porque los mapper dios que hacemos son un poco de broma, son muy sencillos, cuando quieras hacer un mapper dios guay, pues vas a necesitar librerías segurísimo. Vale, cheque. Vale, otra cosa que vimos. Nos vemos. Vale, otra cosa que vimos era el contador de Max, los paseo una captura Bluetooth, de los Bluetooth de este año, del año pasado, no recuerdo. Y había que analizar la había que ver cuántas Max únicas, teníamos en ese listado, ¿no? Entonces, hay aquí un montón de código, porque quería comenzar los distintas opciones, no sé si esto es algo más grande. Vale, entonces, primera opción, esto era el contador de palabras básico que acabamos de hacer, ¿vale? Muy muy muy sencillo, esto no. No nos interesa. Este cacho de archivo es para, perdón, estas líneas de código es para ver un archivo de texto y recuperar los que estaba pensado para aquellos que no tuvieran clases de jadoo y tuvieran que leer esto directamente desde archivo. Porque iban a hacer el mapper, a mano y el reducir a mano. Vale, si habéis visto el archivo, este log de Bluetooth, veréis que cada captura está compuesta de unas cuantas líneas. No nos interesan la mayoría de ellas, de hecho, son los intereses a la línea que empieza por dirección. Entonces, hay un método para los strings, para las cadenas que es, empieza por y siempre va a empezar por dirección. Vale, súper sencillo. Entonces, podíamos capturar las líneas, podíamos tratar las líneas que empiezan por dirección. Si la línea empieza por dirección, entonces la tratamos y finalmente emitiremos un print. Si no empieza por dirección, pues no emitimos ningún print, no es necesario siempre generar parejas clave valor. Yo estoy buscando un dato, pues si no está ese dato, pues no hay. En las bases de datos, pasa lo mismo. Si tú haces un cel, buscando un web y de no sé qué, y no hay, pues no te vuelvo nada, no pasa nada. Y además, bueno, ya tenemos la Mac, en la siguiente evolución, acordaros que la clave de MapReduce es que los MapReduce impriman parejas de clave valor. Esto no es una pareja de clave valor, esto sí se puede considerar una pareja de clave valor. Porque los Reduces, o es obligatorio, que emitan una pareja de clave valor. Los Reduces lo necesitan. Los MapReduce pueden ser muy finos, pueden hacer cosas bastante más finas. Hasta ahora solo buscábamos palabras y ahora estamos buscando Max. Pero podíamos buscar solo Max con que tengan un RSSI y la potencia. Menor de menos 45 de Cibelio, es como al revés, menos 90, no hay intentes conectarte porque no vas a llegar y menos 30 es que lo tienes detrás de la oreja. En ese en ese rango nos movemos en wifi, en telefonía, yo creo que menos 130 hablas por teléfono sin problema. Pero en wifi, a partir de 80 y mucho 90, es el nombre de la wifi y ya está tenote, pues con el 90. Por ejemplo, si quisieramos mostrar IPS únicas que han estado en algún momento con una potencia menor de 45, muy cerca, pues lo podíamos hacer de distintas maneras. Esto es la dirección. No recordara como lo hice, pero para que veis que se pueden hacer más cosas, ¿no? Si se cumple las condiciones que ponemos, pues entonces enviamos. Lo que quiero decir aquí es que esa pareja que nosotros creamos en el map puede ser super específica. Qué más? Archive, stream, dirección, este, esto, como línea es un string, esto es un rango desde la posición 11 en adelante, porque ya analicé este archivo de texto y hay 11 caracteres que yo no uso y a partir de aquí solo está la Mac, pues ya me quedó con la parte derecha, es una alternativa. Bueno, y ya está, me quedé con este porque era un poco el que pedía el venunciado, ¿no? Las mac únicas que hay, entonces de todo ese chorro de datos, yo solamente lo único que me fijó es que si esa línea empieza por dirección, captúlo lo que queda en su parte derecha y genera una pareja clave valor y la lanza. El código es super sencillo de este map, fijaros y es algo más complicado si hay que ver más cosas. El radioser. Bueno, el radioser en este caso, bueno, es igual, no hay mucho cambio aquí que con un contador de palabras. Con todo el acero, para la anterior ninguna, hago el string, el split por la T, me quedo solo con la clave, hago el primer bugle, el primer f, la primera condición para ese caso especial de la primera iteración y después simplemente comprébo si es la misma que el anterior, si es así, voy sumando y si no imprimo y actualizo la siguiente iteración. Y finalmente volvó a imprimir la que me queda en la recámara. Entonces, el contador de Mac, la complejidad que tenía era que ahora cada línea, o sea, ahora iba a ver líneas las que ya no trataba. Antes por cada línea enviaba varias en el contador de palabras, por cada línea enviaba varias parejas de clave valor. En cambio, en el caso de los archivos, los lock, bluetooth, hay líneas en las que no envió nada y hay otra línea en la que envió un único pareja clave valor. Es una cosa distinta, muy sencillo. El contador de Mac y el contador de detrás. Bueno, vamos con el contador de detrás. El contador de detrás, lo objetivo era hacer una práctica, si un poco de juguete, en la que, en un texto, en lugar de contar las palabras, contáramos las detrás. La idea es que si nos dicen que un texto tiene muchas uvedoles y muchas haches y muchas h, pues es probable que pensemos que no está escrito en castellano. Entonces, tal vez con la frecuencia de aparición de las letras, seríamos capaces en un texto suficientemente grande, y los capaces de determinar el idioma. No vamos a llegar hasta ese punto, solamente estamos gestionando la parte de Macreatios. Entonces, si todos habéis utilizado un chagetet para ayudaros que está perfectamente validos, os habrá dado una librería que seguramente te hace esto súper bonito. Pero os quería enseñar este caso, porque hacerlo a mano tampoco es demasiado complejo, lo que pasa es que hay que tener claro que es lo que quieres, esta es la esencia. Si lo piensas, analizas un poco el caso y los estudias, entonces al final te das cuenta que no hay tantas posibilidades. Es como el tres en raya que hiciste con Alejandro al principio. Hay pocas situaciones finales, o sea, solo puedes ganar si tienes la misma X, si tienes la misma Y o las dos diagonales. Entonces, se puede gestionar con casos sencillos. Si no tenéis tiempo, chagepete. Chagepete os va a dar una librería o no recordarán muy bien que os ofrecía. No sé si lo tengo aquí notado. Pero bueno, a todos nos daría chagepete la misma solución, una librería súper óptima, súper buena para hacer. Pero no es tan complicado, porque realmente la idea era un poco que las asma yúsculas y las asminúsculas contaran como una A, porque distinguir más yúsculas y minúsculas para la frecuencia no tiene importancia, no tiene sentido. Y tal vez las A's con acento y o sea, las vocales con acento y las dieres y todas estas cosas tampoco deberían ser importantes para la frecuencia de actualización. Yo consideré que no. Entonces, realmente casos especiales que yo me diera cuenta igual que se me escapa alguno, pero hay estos. Yo voy a tratar todas las letras en mayúscula para no complicarme y duplicar el trabajo para mí todas van a ser mayúsculas. Y solamente tengo que buscar cuando sea una, preocuparme de que no sea ninguna de estas y poner una, si acaso sea alguna de estas, poner machacari, poner una A, la A y la A y la A. Que ellos empanos se me ocurren más casos, ¿no? Ah, no, mira, sí está el borrito de los franceses. Bueno, pues están todas, seguro que me queda alguna, pero no es importante. Entonces, defino estas constantes, estas variables, hago una chapuzada por cada línea, si es un carácter, lo pasa mayúscula y si el carácter está dentro de esos prohibidos, si el carácter está dentro de los prohibidos de A, lo machaco por una A, si el carácter está dentro de los prohibidos de los machacos por una A, no hay una A o una A. Vale, esto no es lo que enseñéis a Alejandro porque seguro que me mata o se ríe mucho de mí, pero es lidástico y se entiende bien que es un código, bueno, se entiende lo que hace el código. ¿Y por qué luego la tenden aquí? No sé, no sé por qué lo tengo aquí. Bueno, mi cabeza estaba ir poniéndolo progresivamente, pero quiero ir rápido porque no me quiero quedar a dormir, por eso es lo comentar si lo entiendo. Vale, este código se supone que lo que hace es leer todo el texto y recorrer la línea, la línea es un string, yo la recorro, pero ya no tengo que partir la en palabras, para que la voy a partir en palabras y yo al final lo voy a considerar toda una cadena, entonces la voy recorriendo y en cada recorrido sólo me refijo si es un carácter azabético, si es un espacim blanco, pero la innovación, una escomilla está, no lo trato, vale, entonces esto es una método de string que proporcionaba Python pues por Palante. Lo pasa a mayúsculas con la misma idea para ya no tener que poner una distinguía de mayúsculas de minúsculas y lo comprobo por los casos especiales si coincide machaco. Y para cada iteración en la que estoy leyendo un carácter pues si finalmente es lo imprimo, ah ya me acuerdo que va a hacer aquí, que esto también lo quiero que meter, aquí me quedo, pues si es un caso especial, pongo el caso genérico y lo imprimo, vale, ahora bien la pequeña reflexión a ver si me seguís también, con esto lo que consigo, con este más prodíos lo que consigo es poner cuantas veces aparece la letra A, la letra B, la letra C, cuantas veces se parece. Pero realmente que aparezca 100 veces o 1 millón de veces a mí eso no me dice nada porque no sé cómo de grandes en texto, no me dice nada. A mí me diría algo si el lugar del número de veces me aparece el tanto por ciento de veces que aparece esa letra. Entonces en un ejercicio avanzado parece mentira pero en un ejercicio avanzado a mí me gustaría que en lugar de devolver un recomo resultado 350 me devolvieras 17%. Bueno 17% yo creo que es mucho pero 4%. 4% de las veces en este texto ha parecido la letra S. Si tú te para saber eso en cómo la harías en la época de los romanos teniendo un montón de esclavos inteligentes a tu disposición, pues pues es difícil, es difícil porque tendrías que hacer varios recorridos, uno para saber, al final eso es una edición que tienes que hacer, ¿no? Pues tienes que saber cuántas letras hay. Si yo arranco una hoja del libro y te la de a ti para que la proceses o trabaja del libro y se la di otro compañero para que la procese y otra hoja del libro todos me vais a decir cuántas has ahí en vuestra hoja pero ninguno de vosotros será capaz de decirme cuántas letras tiene el libro. Entonces, menos mal que no es parte de mi materia pero yo no sé si matemáticamente se podría, se tendría sentido calcular el porcentaje en tu hoja y después unirlo de alguna manera al porcentaje de mi hoja haciendo no sé la media o es que no tengo ni idea, tendría que pensarlo si matemáticamente esto tiene sentido pero vamos a suponer que no tiene sentido, que vamos a sumar todas las as porque en tu hoja había pocas as en la mía había muchas cosas. Entonces lo idea sería contar todas las letras que hay, el total de letras que hay y después ya sabiendo cuántas has ahí pues hacer la cuenta, ¿no? Y ya tendríamos el tanto porción. Si os dais cuenta hacer esto requiere de dos pasadas, entonces tendríamos que necesitar un mínimo de dos trabajos, un mapre dios a lo mejor para contar las palabras y otro mapre dios. Para contar las letras ya con las palabras sabidas, ya con el número de letras perdón sabidas. Entonces, una idea que os si va a dar era para cada carácter, para cada carácter, lo equipo como la, una aparición, la z, una aparición, la f, una aparición, pero el lugar de solo imprimir una pareja clave valor en el lugar de solo imprimir la z, una aparición y el total, una aparición. Fue claro que es una cadena total, la cadena total, una aparición. Entonces lo que tendría en mi nube, en mi jado sería un montón de parejas valor, letra aparición, letra aparición, letra aparición, letra aparición y también tendría por ahí flotando un montón de total aparición, total aparición, total aparición, total aparición, total aparición. Lo dais cuenta, o que tendría muchas as y muchas ves y muchas ces, pues también tendría muchos total. ¿Cómo podría gestionar esto desde la punto de vista del reducer? A ver, si lo gestione, si esté, no, no lo gestione, era para comentar. Vale, el reducer habría un reducer al que le llegaría a los totales, uno, uno solo le llegaría a los totales. Bueno, si es un diario muy grande o una colección muy grande igual a dos reducerle, le llegaría a los totales, pero finalmente tendría un resultado total, todas las a, todas las ves, todas las testes, todas las d y todos los totales. En mi primera pasada ya tendría todos los resultados, pero aún no tendría el porcentaje, no tendría porcentaje. Entonces necesitaría un segundo trabajo, un segundo trabajo, al que le pasaría esos datos, al que le pasaría esos datos y el dato del total ya se lo podría pasar directamente al contenedor. Lo podría gestionar, ya es una cosa muy sencillo, lo podría gestionar tanto con un mapper porque soliría una pareja por la a, por la sol iría una pareja, por la vez, sol iría una pareja, por la c, sol iría una pareja. Entonces el mapper me cogería esa a con su valor, el total que le he pasado a través del fae, en ese segundo trabajo, el total ya se lo había pasado como una constante, me hace la cuenta e imprime el total, perdón la letra con el porcentaje. Un mapper me lo podría hacer ya perfectamente, no haría falta el reducer, el segundo mapper, no haría falta un segundo reducer, porque los datos de entrada no se repiten, no haría falta ni barajar ni ordenar ni nada. No sé si me seguís. Perfecto, sumar en el segundo mapper, si, a lo mejor alguien diría, pues yo lo quiero sumar en un reducer, pues también está bien. En este caso concreto está bien, porque los datos de entrada a ese segundo trabajo ya sabemos cómo son, van a ser el alfabeto y como valor las veces que han aparecido y por detrás digamos que estoy metiendo la constante de total. Todo esto es tu, por cada parece, haces la cuenta que tengas que hacer y me darías la, me darías el resultado. Esto en MRJOP por ejemplo, MOLA, porque como lo tienes todo un archivo, un mapper, un reducer y otra vez un mapper. Y ya va solo, va por orden, es como un programa sencillito, en cambio con Hadoop streaming no puedes hacerlo, tienes que lanzar un trabajo y después un segundo trabajo puedes que me script para hacerlo y después hay programas como Q y algún otro que te permita pequeños scripts, pero pigg ya no se usa, hay algunos pequeños programas, utilidades que te permiten hacer este tipo de script, no conozco esa parte de Amazon, pero me ha puesto un brazo a que MR también permite encolar trabajos, ¿no? Hace esto que queremos, ya hemos visto cosas más allá, hemos visto mappers, hemos visto radioses que van cambiando incluso que pueden complicarse un poco. Contador de letras, contador de max, este mapper 2 que tenía aquí, tiene una muy interesante. Que tenía este interesante. Ah, el segundo mapper, claro el segundo mapper que os estaba comentado, segundo mapper tomará los valores por ahí, de cual no lo vemos y hacer lo que tenga que hacer y lo envía. En este caso concreto, hay que hacer un mapper, hay que hacer un radioser y nuevamente un mapper. En este caso concreto, ese segundo mapper puede ser un radioser y yo no sé si para una carga tan pequeña en la que sabes que vas a tener un alfabeto que son 28, 29, 30, no sé, 30 parejas clave valor más el total, pues a lo mejor no merece la pena hacerlo en distribuido, a lo mejor, haces un trabajo solo mapper dios y los finiquitas con un pequeño script, os dais cuenta, entonces la clave de esto mapper dios no es la solución para todo, eso solo la solución cuando los datos son masivos, no entra en un ordenador. Cuando tú tienes un excel, de mas de dos gigas que no puedes procesar en tu ordenador, tienes que programar, tienes que hacer un script y programando, no hay ningún problema. Pero cuando la cosa esté de los, no sé cuántos gigas tiene tu ordenador, 16 y 32, cuando la cosa esté de ahí, no, por supuesto ya no puedes hacer con excel, ninguna herramienta de ofimática y la parte de programación requiere de una programación ya no solo con la lógica de lo que tú tengas que hacer, sino con la lógica de la lógica. La lógica de sistemas, la que tienes que partir los datos en algún momento, primero procesar uno, guardarlos en el disco, liberar la memoria, volver a cargar otro y eso es muy duro porque antes emce a crecer la memoria a piñón, pero ahora es campo abierto, entonces hemos perdido que la memoria es finita y no siempre se gestiona bien. Entonces cuando los datos ya son, ya no cabe en el ordenador, entonces ahí es cuando entra mapre dios. Voy a hacer aquí unaificación para seguir con el de Mario, pero después voy a volver exactamente este punto. Voy a hacer unaificación muy rapidísima porque me quiero ir aquí a la parte de Hype. En este módulo hay una serie de herramientas que se propone ver, una cosa desverjado y después hay un montón de herramientas que funcionan sobre Hype. Hay que elegir algunas, el módulo ya está desfasado, nombre a muchas que ya no se usan, Hype es de las pocas que se siguen usando. Hype es un motor, no se llama un motor, pero bueno un motor, ese cual que trabaja sobre mapre dios, es decir, tú instalas Hype, le dices mi la Hype. Voy a usar HDFS para dejar los datos y quiero que sobre esta carpeta me ejecute esta sentencia SQL. Sele nombre, fron, esta tabla, el RSSI sea menor de menos 45, es una SELEC normal de SQL. Lo que hace Hype es transformar esa SELE en un mapre dios, en el que sea, esa traducción de SQL a lo que estamos haciendo nosotros. No sé si os dais cuenta que con el mapre dios que estamos haciendo nosotros, casi casi se podrá decir que estamos haciendo consultas. Estamos viendo cuántas IP es única SIDE, cuántas veces aparece una letra, dime las Mac que estuvieron cerca del punto de acceso. Si os dais cuenta, mapre dios sirve principalmente, no sólo, pero sirve principalmente para más de datos, para consultas de más de datos. El lugar de tener que usar un programador que sabe programar, pero igual no sabe, yo creo que es estadística o cosas de esta rara, pues la gente vea que había una necesidad y entonces desarrollaron Hype. Pero su men de Hype es SQL sobre datos de Hype. La misma consulta que hicimos de IP es perdón Mac únicas, la podíamos haber hecho con Hype. De Hype hay que saber poquitas cosas, están en instalación, que está documentada ahí en el PDF, básicamente hay que configurar par de cosas. Y cómo se usa? Hype hay varios clientes, nosotros usaremos Hype, estaba el pipeline, Hype, nosotros usaremos uno el que ha quedado como más potente, porque el otro era solo para usar en local y este lo podemos usar desde el modo. Y aquí la chicha un poco está en distinguir, es lo único que se sale de SQL de Hype, tablas internas y tablas externas. Hemos dicho que cuando hacemos un MacreDios porque debajo de Hype hay un MacreDios, no lo olvidemos. Cuando utilizamos MacreDios, los datos están siempre, siempre, siempre, según los 100% en HDFS, siempre. Y la salida también está pero los datos de entrada están en HDFS, entonces Hype distingue, tablas internas y tablas externas. Ahora me hacéis dudar, pero como esto lo vais a buscar con control F en el PDF, no me preocupo nada. Si no es como lo digo, es al contrario, no es importante porque lo vamos a olvidar todos, el 21 de junio ya lo hemos olvidado. La diferencia entre las tablas internas y las tablas externas es que las tablas internas apuntan directamente al HDFS de JADU. Es como un enlace, como un, como se amaste de Windows del escritorio, un acceso directo. Es como un acceso directo a los datos que están en HDFS, ¿no? Entonces cuando creas una tabla o cuando le liminas, cuando le liminas una tabla, pues el limina es el acceso directo, pero los datos siguen estando en HDFS, no pasa nada. No se pierdo. Yo por ejemplo podría utilizar la Hype contra los datos que ya tengo en mi carpeta entrada de HDFS. Y puede hacer una consulta que me haga un drop de esa tabla. Me puedo crear una tabla con los campos que a mí me de la gana y cuando no me guste le hago el drop y la limina fuera. Eso sea las tablas una, las internas, por ejemplo. Y las tablas externas es cuando tú cargas los datos directamente en la carpeta de Hype, que esto se configura. En la parte de configuración de Hype le creas una carpeta propia para que haya, haga sus cosas para que las tablas intermedias, las vistas, todas las cosas de ese cual queden ahí guardadas. Si tú cargas los datos en Hype directamente esos datos están en Hype. Cuando tú haces un drop y el limina es la tabla, el limina es completamente los datos. Es verdad que esos datos estaban en HDFS, repinicados por ahí, pero en el momento que tú lo borras no hay ningún acceso directo, nada, se borra. Básicamente es la única cosa así un poco distinta de ese cual que os pueda llamar la atención. Por eso hice la pausa en ese momento porque yo creo que en este momento ahora ya podéis un poco ver que más precios sirve para hacer consultas muy principalmente y que estaría guay poder hacerlas en ese cual siempre que se pueda, sin que sea así un poco estructurado. Pues Hype cubres la necesidad. Entonces está todo en el PDF, no había tareas más allá de las que queráis probar vosotros para hacer una consulta y las devuelve como el Warbench Esteve de MySQL, así como una tabla de MySQL, una tabla de MySQL, pero bueno, lo que estamos acostumbrados. Eso si lo haces por comando y también lo puedes meter dentro de tu programa, como una vez que huele normal y correcto. Vale, volvemos para atrás, madre dios, ya para ir enfilando el fin. Bueno, sólo los voy a dejar caer y las voy a intentar comentar así un poco por encima porque no sé si podríamos hablar, si no podríamos hablar, si estoy lidado o la playa o donde sea, entonces lo voy a comentar si surge el debate, pues perfecto y si no surge, pues tenéis tenéis la idea. Entonces, imagina los que tenemos acceso a todas las cámaras de los parkings de mercador con una foto de cada matrícula. Entonces, son, supongo que bastantes datos y además son imágenes o cosas pesadas. Bueno, y resulta que nos preguntan cuántas veces se entra a ver cuántos coches han entrado en nuestras tiernas o bueno, no sé, alguna pregunta, pensé en alguna pregunta típica de consulta que os puedan hacer. Y tenemos que gestionar, entonces, sólo teniendo las imágenes, no sé qué ofciones nos proporciona el mercado, pero vamos a suponer que no encuentras ninguna y dices, bueno, pues hay que implementar. Entonces, te van a dar un montón de higlas y higlas de imágenes con sus direcciones, con sus nombres. Y tú tienes que procesar esas imágenes, tienes que entrar en la imagen, tienes que utilizar alguna librería para detectar matrículas y leerlas. Ocaras o caras, o pensé o ve detecta caras. Bueno, hay un montón de librerías para mil millones de cosas, entonces, cada una de esas imágenes hay que pasarla, pues una de esas librerías para obtener el dato que nos interesa, con el objeto de localizar. Y después lo podríamos en la terrena base de datos o podríamos contarnos otros. Bueno, si lo hacemos así y lo implementamos en nuestro ordenador, echará un rato, echará un rato. No sé si alguna vez habéis abierto, ventana sin querer, pues he hecho un rato. Procesar una imagen y otra y otra y otra y otra, he hecho un rato. Y a lo mejor es nosotros lo queremos rápido, queremos los resultados lo más rápido posible. No le vamos a decir al señor Mercadona que nos compre un ordenador mejor, porque aunque nos compre un ordenador mejor, vamos a estar atados bastante cerca del... No vamos a mejorar mucho por más que echemos pasta en un ordenador. Entonces, llegados a este punto, este es un problema típico de filosofía, big data. Nos que sean z-bytes, nos que sean muchísima información, pero sí que son datos pesados que estaría igual poder procesarlos de manera distribuida. Un problema que aquí nos interesa, pues un poco la capacidad y un poco la velocidad de respuesta. Acordos que había como tres ejes y tenemos que cumplir con dos. Aquí viene un poco el cómo me gustaría tener una charla con vosotros, allí sentaditos en el charlito tomando una cerveza y cada uno haciendo una lluvia de ideas proponiendo como haría cada cosa. Por ejemplo, la que se me ocurre después de este curso sería bonito pensar en un más radio en el que podríamos tener todas esas imágenes. En un HDFS, tenemos que tener un listado de direcciones relativas, de cada una de esas imágenes. Y mandar esas imágenes o ese listado de imágenes a muchos mappers, tantos como tuvieramos en nuestro cluster o en nuestro MR de OVW. Ahora el trabajo ya no era procesar todas las imágenes de los mercadonas de España. Ahora el trabajo era procesar un cachito así de las imágenes de lo que fuera un cachito así, a ti, en tu nodo, te ha tocado un cachito así, esto lo puedes hacer en un tiempo razonable. Si aún quieres que sea más deprisa, pues el cuestión de meter nodos, y más nodos y más nodos y más nodos, hasta que es sus cachitos y si problema tan grande, vaya bajando. Entonces, la gente muy lista, se abestima de estas cosas y con las experiencias, sobre todo, se abestima de estas cosas. Pero bueno, supongamos que tenemos el cluster adecuado. Pues ahí estaría igual que el mapper, recorriera esos datos y por cada una de las imágenes la aplicar a la librería que fuera, detectar a la matrícula y generar una pareja clave valor en la que, por ejemplo, se me ocurre, pusiera la matrícula y un uno. Al mejor a ti se te ocurre que puede poner la matrícula y el lugar del uno, el time stamp para, bueno, por lo que sabes, cuando, cuando entrada. Bueno, pues depende, si nos piden la hora de máxima fluencia, pues igual el time stamp es interesante. Si nos pregunta si alguien ha entrado y salido más de una vez al día, pues al mejor con un uno también es más interesante que el time stamp. Bueno, depende del problema, estaría guay saber qué pareja clave valor tiene que salir de cada imagen. Uno o varias. Uno o varias. No sé, la matrícula y un uno, el número se nos cabían el coche y un uno o lo que queda es. Y después en el reducer queríamos con eso, contarlas, hacer una media, etcétera, etcétera. Otro ejemplo que se me ocurre. No sé, uno. Bueno, esto es un ejemplo típico del log de Apache que os comentaba y se ve en jadalista. Es un ejemplo típico del log de accesos que tiene Apache. No te dice el IP desde la que te conectas, el time stamp, lo que te descargas, el código 200, todo bien, ok? Y esto creo que son bytes de ese envía. Creo que sí, no estoy seguro, creo que sí. Bueno, pues veo aquí un lado uno, un lado dos, un lo que sea entonces. Pues deja ahí en el aire. ¿Cómo podríamos hacer si, por ejemplo, Google en la página de Google pusiera tres botones como Matrix, dos pastillas de Matrix, bueno, pues tres botones, rojo, verde y azul, ¿no? Con un mensaje que dice que tienes que elegir uno y solo puedes pinchar en ese que lijas, que no veas los otros. Y Google quiere saber cómo de buenas la gente o como de obedientes la gente y ver si efectivamente solo pincha en uno o en dos o tres. Entonces Google, al final del día te va a decir tú que has aprobado este módulo, te voy a dar todos los archivos log de mi página web de todos mis servidores que tengo repartidos por ahí. De todos los accesos de día y que son muchos, son varios gigantes, solo de lo, solo de lo y cada uno de estos, preocupa muy poquito. Y quiero que me digas cuántas y pes, cuántas han entrado solamente en uno de los botones, en el botón rojo, en el botón verde, en el botón azul, me da igual en cual, solo en uno, solo en uno. ¿Solo para el post-estas? Este es el reto que dejo ahí en el aire guiño, guiño, codazo, codazo. ¿Queríamos cada uno de nosotros? Pues hay que pensar, claramente es un mapretyuse, ya solo a mente hablar de los servidores de Google, ya parece evidente. Entonces vas a tener un montón de líneas como estas. Vas a tener un montón de líneas como estas, entonces, la recupero por ahí. Vamos a tener la IP, la fecha que nos van a dar igual y vamos a tener, pues, imagínate, aquí el recurso este, imagínate que es un botón, un jote RPG o lo que sea. O el HTML, dé igual. Primadrina de que estamos localizando en pseudo código, vamos a hacer todo en pseudo código. El rojo, el azul y el verde. Entonces, los van a ir llegando líneas de estas, un montón de líneas de estas, y nosotros esta, la vamos a ignorar, esta también, esta también, esta también, esta también, pero desde en cuando va a llegar una línea que ponga rojo, esta nos interesa. Tenemos que capturar que esta IP ha visitado el rojo. Bueno, vamos a seguir llegando líneas, pongo, pongo, pongo, pongo, y a lo mejor nos vuelvas a salir la misma IP y ha vuelto a visitar rojo. Se puede visitar tantas veces como quieras, pero el compromiso es que solo entre el rojo, eres fiel al rojo. Sigue llegando líneas, a lo mejor en otro mapa, esta misma IP, en algún otro momento, por el resulta que llega el verde, ha visto el verde, que estar atento porque esta IP ya la eliminamos, no nos interesa, ha visto el rojo, pero también ha visto el verde. Entonces, no es confiante. Bueno, pues, imaginares que os llega, imaginaos que os llega a hacer el map, yo creo que es relativamente sencillo, pseudo código, mi interesa, cero, python, porque lo vamos a hacer a mano, entonces, no mi interesa. Parece que es un poco, pero no interesa. Entonces, el mapa es bastante sencillo, porque va a seguir leyendo líneas, la primera parte, la primera parte es la IP, puede decirme considero que el primer guion se para la IP, me decime que las IP es todas tienen tres números, o sea, tres cifras en cada número, esa es un poco bogevino. O a lo mejor sabes que existe una librería, RE, destrucción de regulares, que te localiza a esto y te lo que sea, yo creo que en este nivel todos somos conscientes de que con más o menos trabajo, todos podríamos conseguir esta IP y si detectamos que en el resto de la línea, rojo, verde, azul, también detectar, vamos a hacer una cosa sencilla. Entonces el mapa, el mapa yo creo que podría ser una cosa sencilla, que a lo mejor nos devuelve un IP, bueno, pues no pongo un IP, vamos a imaginar que pongo la AP, pero aquí vosotros veis un IP, 157.2.8. Y que en esta ocasión devuelve, devuelve rojo, este IP ha visitado el rojo, después esta misma IP también ha visitado el rojo en otro momento, después esta misma IP ha visitado el verde, ya está llano, nos vale. Y después, he estado 3P, ha visitado el rojo, y ya no tenemos más datos. Entonces, en este escenario, nosotros al señor Goga, solo le devolveríamos la IP, V, mira, el V es el único que ha elegido un color y se ha mantenido fiel, suerte porque solo lo me siento, el AP parecía que se iba a mantener fiel, pero su cumbió al final y el gion, entonces no lo vamos a devolver. Bueno, pero esta es parte que nos devolverían los mapes, que yo creo que es bastante tribiada, aquí la chicha estaría un poco en el reducer. Bien, ¿cómo haríamos el reducer? Bueno, pues nada. Como siempre, empezaremos por un bucle en el que leiríamos el terminal, las parejas clave valor que los mapes nos van enviado, entonces, mientras nos vayan enviando map, parejas clave valor, nosotros citeramos y cerramos y cerramos y ceramos. Entonces, si, si, si, si hay más líneas, nosotros necesitamos leer algo. Vale, en su momento necesitamos leer la clave cuando eran letras o palabras, ¿vale? En su momento necesitamos leer la clave. Ahora necesitamos leer la clave, necesitamos leer la IP, va a ser la clave, pero también necesitamos leer el valor antes de ser un uno y ni lo usábamos, pero ahora sí que el valor es importante, porque necesitamos saber si le rojos, si le verde o si le hace, es importante. Entonces, aquí obtenemos la clave valor, hacemos el estrépe, explíte, hacemos toda la pesca que hay acá, y definimos cuál es la clave, vale, de hecho no me da más clave ya, vamos a ver. Le voy a poner IP y color, que quede más claro, vale, pero ya entendemos que es cada cosa, esto será la IP y esto será el color. Vale, entonces nos llega la primera pareja clave valor, esta misma y conseguimos la IP, que es este IP y el color, que es este lojo. ¿Qué hacemos? ¿Qué hacemos? Antes sumábamos uno, antes hacíamos esta y vivíamos felices, pero no solo es sumar uno. Hay que hacer cosas, hay que pensar, entonces, aquí es donde me gustaría dar una pensada, que pensar, que abrir un debate, abrir un tal, pero, después de las cuatro razas del otro día, hoy me levoréis algo más suave. Entonces, ¿qué haría yo? ¿Qué haría yo? Pues yo utilizaría una cosa muy importante, muy útil de Python, que son los conjuntos, los conjuntos, serte. Un conjunto es una estructura de datos, es la que como un arraio, tú puedes meter datos, pero tiene la ventaja que no hay datos repetidos, entonces si tú metes 25 veces, el mismo elemento, solo consta una vez. Si yo meto rojo, en el conjunto, se guarda el rojo. Si yo meto verde, en el conjunto, se guarda el rojo y el verde. Si yo volvamos a meter rojo, como ya están en el conjunto, que le guarda, entonces, rojo y verde. Estos miliútipos, por ejemplo, para IP es únicas, IP es únicas que han visitado la página. Pues chicos, toca así, creo que lo hago en un mapa, solo, porque, bueno, a final había que juntarlo, entonces no, pero si pensamos en distribuido, pero básicamente esto es leer la IP y meterla en el conjunto. Si ya estaba, no pasa nada, ¿qué de igual? Y si no estaba se añade, entonces, todas las, voy recorriendo todo el log, lo voy metiendo en el conjunto y al acabar, digo, muestra print el conjunto, pues ahí están todas las IP's únicas que han visitado esta página. Los conjuntos es una herramienta súper potente para estas cosas, si no, te diréis que controlarlo, meterla en una RAI y por acá de IP, recorrer en la RAI para ver si está, utilizar un IN que también puede ser interesante y decidir si los metes son los metes, eres tu el que controla la repetición, pero en un conjunto la repetición ya está controlada por la propiedad naturaliza de tipo de datos, por lo cual. Es interesante, vale. En Python es set, pero a mí con que en su código me pongáis con junto, yo os aplauro. Vale, pues entonces aquí lo ideal sería meter los datos en un conjunto, vale, por cada IP, por cada IP, meter los colores que visita ese IP en un conjunto. Vale, bueno, entonces ya sabemos aquí que todas las IP's me van a llegar juntas, todas estas as, todas estas as, me van a llegar juntas. Entonces yo en algún momento tendré que cambiar el contador o las decisiones que tome cuando me llegue otra clave o otra IP, ¿no? ¿Cómo se cuando tengo que dar ese salto? Pues tengo que dar ese salto cuando me llega un IP distinta del anterior. También una IP distinta del anterior tengo que hacer una renovación, ¿no? Eso va a pasar siempre, pues siempre no, en el primer caso ya sabemos que es un caso especial que en el mojoso puede encontrar otra manera, no digo que no, pero lo que todos os digamos sería este, que hay que hacer un poquillo de trampa, entonces la trampa consiste en, pues no variable anterior, no, y aquí comprobar si anterior es igual al mol. Si es que sí, estoy en el primer caso, que es un caso especial, en el que digo que anterior es igual a la IP que esté tratando ahora. Y si es que no, no hago nada. Lo voy a poner otra vez a amarillo, porque este es un caso que después sólo voy a tratar una vez, no, nunca más. Para esto ya suponemos que verlo a trago por ahí, a ver donde los puedo poner, anterior IP y con junto. Vale. Bien, siguiente caso. Ahora ya sí, ahora ya puedo comprobar si la IP es igual al anterior. Si la IP es igual al anterior, estoy en una nueva aparición de SIP, no, hizo una consulta y quiero ver ya no, ya tengo filtrado el resto de las páginas, sólo tengo aquí si he entrado en alguno de los colores, eso ya me lo hizo el mapa, el mapa ya me libró de toda la basura, todas las otras páginas que visitaran, no me interesa, sólo me interesa la de los colores. Entonces, la IP A está y P que esté tratando, visito otra página. Pues sí es que sí, añadir color al conjunto. Entonces, vamos a poner rojo, pues lo pongo aquí, rojo. Al anterior que no lo estoy actualizando es una A y la IP es la, que no lo utilice. Vale, y ya está, ya he hecho una iteración, vuelvo arriba. Siguiente heriña, ¿qué es esta aquí? Esta que estoy tratando ahora. IP y color, la IP esa, ya la tengo aquí y el color, color, color, color, rojo. Vale, ya lo tengo, esto amarillo, ya no lo hubiera tratado porque sólo para el primer caso, entonces la IP es igual al anterior, la A es igual a la A, sí. Entonces, me vengo por aquí y le añado el color al conjunto. ¿Qué color es? Rojo. Rojo, ya está en el conjunto, con lo cual aquí no pasa nada, está sido transparente. Vale, la iteración rápida. Siguiente caso, vuelvo a subir, vuelvo a tener la IP y el color, la IP es la misma y el color en este caso es... Verde. Vale, bien, la IP es la misma que el anterior, la IP sí es la misma que el anterior, entonces me damos por aquí, me damos por aquí y añado el color al conjunto. Como es verde, no está en el conjunto pues se añade. Muy bien, volvemos en la iteración, consigo la IP y el color, la IP en este caso es la B, la IP en este caso es la B y el color es el rojo. Entonces, todo dice aquí. Vale, lo tengo. Siguo por aquí, la IP es igual que el anterior, la B es igual que la A, no. Entonces, me tengo que ir por este camino. Cuando yo me voy por este camino, sé que es que ha cambiado la IP, ha cambiado de IP, con lo cual, los datos de la anterior yo ya los tengo. Es gestionar, tengo que imprimir los datos del anterior, a ver, pero antes hay que guardar el color y luego ver si es distinto y si es distinto se descarta y si no se sigue. Si es distinto, si es distinto se descarta. Ya cambias, claro, pero no lo puedes descartar aún porque te van a seguir llegando parejas de clave valor, el color no está ordenado, los valores no están ordenados. Digo Manuel, que, por ejemplo, si aquí, si aquí te viniera a otra con un rojo, tu en el verde no puedes tomar la decisión de ya no quiero saber nada más de las As, porque te va a llegar otra pareja con una A. Entonces, tendrías que meter código por aquí por algún lado, si me llega a una clave que ya he desechado, no la tendras, había que meter otro IP por ahí, que está bien. O sea, te he dicho que no, pero porque no es mi idea, pero está bien. Podrías tener, guardar un válida, mientras todo vaya bien, y en el momento que no haya bien, no válida. Pones un bulegano por ahí lo gestinas de alguna manera, y si te vuelvan a entrar esa clave, pues ya la limina desde el primer momento y te ahorra recorrer el tarpón. Podés ser, no sé cómo quedaría, es que tenemos la pantalla. Simplemente para evitar los conjuntos, simplemente. Para evitar los conjuntos, vale, perfecto. Vale, pues genial manual, me gusta, me ha encantado que haya otro alternativo para que se vea que hay muchas. A mí me interesa a la de los conjuntos, porque realmente se ve que hay muchas cosas que ya te puedes desentender. No tienes que recorrer, para ver si estaba, tener que controlar. Entonces, en muchos casos, estos como cuando me enseñaron lo del módulo, vivir y quedarse con el resto que servía para grupar, porque siempre era 0, 1, 2, 3, 4, 5 hasta el cociente, 0, 2, 3, 4, 5, 0, 3, 5. Y para mí eso fue, más temmáticamente como aprender a sumar con llevadas y flipantes. Pues los conjuntos también me han solucionado bastante de espapeletas, pero qué hicimos. En este caso, usar conjuntos no aprovecha el hecho de que esté en ordenado los datos. Me fue una necesitaría de instrucción ordenados. Estás haciendo un procesado de los datos que no... No está por tanada. Es verdad, lo que pasa es que si están ordenados, la ventaja es que sólo tienes un conjunto. Tu utilicias ese conjunto y ahora cuando cambiemos al ve, yo lo voy a hacer a ser recetear ese conjunto y volver a utilizar. Si no estuviera los datos ordenados, tú tendrías que mantener un conjunto por cada clave. Y claro, estoy igual, no se explota, no lo sé. Y de esta manera sólo tendrías un conjunto que reutilizaremos, como la variable contador. Pero que estoy defendiéndome por no perder la silla, pero que tú opciones también me agrada y lo detenerlo controlado. Bueno, entonces, este me lo cargo y vamos a ver. El ve iríamos por aquí, no es lo mismo, entonces me di cuenta que tengo esta parte, que ya tengo que devolver y gestionar la nueva IP. Esta parte, como sé si tengo que devolverla o no tengo que devolverla, porque antes era bastante fácil. Hacíamos el print, ya, con esto y el contador, pero ahora igual sí, o igual, no. Aquí es cuando me toca estudiar el problema y longitud del conjunto, igual a uno. Esto es un pseudocódico, muy infiel, si el conjunto, si el número de elementos, si es la cardinalidad, lo podéis poner como queráis, en pseudocódico, que se enquete. Si el número de elementos del conjunto es igual a uno, entonces lo hecho bien. Vale, este es el que queríamos. Si solo tiene uno, es el que queríamos. Lo imprimiríamos, print, la IP y no es decir color, lo meto. De igual. Y si no, si no es uno, es dos o tres, ha visitado, entonces no hago nada. No hago nada. Finalmente, parece que esto solo no hacer nada, parece que solo lo hacía los mappers. Y aquí estamos pensando en un reducer, que le va a llegar unas parejas de clave valor, que en principio pasaron por el map, pero que finalmente no las hago. Entonces llegamos al mismo punto. Esta parte digamos que ya queda finiquitada, en algunas ocasiones, la envío, cuando solo tiene uno en el conjunto y en otras ocasiones, no la envío, porque he hecho trampa. Podría volver, podría volver, pero antes de volver tengo que gestionar esta parte. Un poco parecido con los retiros que hicimos antes. Entonces lo voy a poner por aquí, el anterior, que tengo aquí, ya no es la, la anterior ahora es la nueva, la IP. Está de aquí. Vamos a poner algo en la versión de Calconada. El anterior es la B, que más cosas hago, el conjunto. Pues yo que sé, lo vacío, lo nuevo y lo machaco, o vacío conjunto, seguro código, lo que queráis. Y añado el nuevo color, añadir color, color, y se lo totario total. Entonces vacío, vacío el conjunto y añado el color rojo. Vale, ya era así, un vuelvo para aquí. Vamos a suponer que yo trabe, y que también es rojo. El B no buena persona. Entonces viene por aquí, consigo la IP y el color, la IP es la B, el color también es el rojo, la IP es igual al anterior, la B es igual a la, la, la B anterior. Sí, voy por aquí, añado el rojo al conjunto, como el rojo ya está añadido, no pasa nada. Y vuelvo a empezar aquí. En algún momento se acaban las parejas clave valor, ya no hay más. Y entonces llegamos aquí, pero tenemos que salir por la parte de ya no hay más. Cuando llegamos a la parte de ya no hay más, estaríamos en este punto, lo hemos procesado, tenemos las cosas en su sitio, pero no hemos hecho esta parte, no hemos decidido si imprimimos o no imprimimos. Nos queda la recámara. Antes nos quedaba una pareja clave valor en la recámara, ahora nos queda dos parejas clave valor. Realmente lo que nos queda es una clave en la recámara, siempre. Bueno, pues aquí hay que decidir si lo imprimimos o no lo imprimimos. ¿Cómo lo decidimos? Antes aquí solo había un print, print del contador, siempre era así, aquí nuevamente hay que tomar la decisión. Si la cardinalidad del conjunto, no voy a poner distinto a ver, es menor que dos, va a vencer en algún caso, ya me voy. Bueno, me estoy con un plato, vamos a asegurar. Si la cardinalidad de conjunto es igual a uno, esto es justo lo que queremos, esto es una pregunta, esto puede ser que sí. Si es uno, entonces lo imprimimos, print, la IP la tenemos aquí. Y el rojo lo tenemos aquí. Vale, tranquilo. Y si este último caso no hubiera sido rojo, hubiera sido azul y subir ha metido aquí y ya no entrábamos por la cardinalidad uno, si es que no. No hacemos nada. Y ya cualquiera de los dos. Bueno, entonces ya modo de cerrar la historia esta. Este módulo, este módulo, al macenamiento distribuido, que lo vimos un poco a lo loco pero creo que con procesamiento distribuido se entiende bien la potencia de todo lo que hay debajo. Después viene ya que se encarga de generar los contenedores, de generar los contenedores solamente en los sitios adecuados, discusadamente como si fuera poco, genera los contenedores con la reserva de procesador y la memoria y el disco apuntando a los datos que hagan falta. Es una cosa muy compleja y sobre eso va el motor de procesamiento. Nosotros sólo hemos visto mapredios. Mapredios es el más antiguo de los motores de procesamiento distribuido pero se es incluso, ya os digo que en AWS en un servicio elastic mapredios que sigue funcionando. Con funcionar esto, esto funcionan Java pero hay un truquito para utilizar cualquier lenguaje que tenga acceso a la termina, que es JaduPestreaming. Con JaduPestreaming sólo nos tenemos que encargar de hacer los mapredios y de hacer los retiuses y cada uno tiene su función. No necesariamente tienen que ir por parejas, un mape de un retius, es posible que haya cosas que solo se hacen con un mape. No se me ocurre pero lo voy a lanzar así, cosas que solo se lo saben con un retiuser si los datos ya son parejas de... No estoy seguro de esto, pero lo que sí es seguro es que pueda haber distintos trabajos, un trabajo de mapredios y después otro, y después otro, los que hagan falta. Y exactamente igual que en las consultas en la base de datos, no recorrer una vez y ya está, hay cosas que hay que recorrer varias veces. Por ejemplo, el de los porcentajes de las ventras. Me decía la pena hacerlo en dos etapas mape dios, no, porque el resultado final de la primera trabajo son 30 parejas de clave valor. Eso lo geste a una calculadora, no hay que ver. La parte del mape, la parte del mape se encarga de tomar los datos en bruto y convertirlos en parejas de clave valor. ¿Qué clave y qué valor utiliza depende del contexto del problema? Cada uno aquí tiene que utilizar su ingenio para averiguar si la clave es esta o es esta otra, o hay que procesar un par de datos para concatenarlos y unirlos y obtener una clave un poco más explícita, más específica. Y los valores igual pueden ser desde nulo, uno, un string o un yzo, lo que necesiteis. Cuanto más complicado sea el valor, más trabajo tendrán en el reducer. ¿A que balancear un poco? Es el mape. Después hay una fase intermedia que los que utilicemos un clas de jadub nos desentenemos, que es que coge todas las parejas que han generado los mappers. Cuando los he sido aquí. Cuando los mappers han acabado su trabajo, no vamos a ver nada. Cuando los mappers han acabado su trabajo y han emitido todas las parejas clave valor, hay entra una parte jadub, que es la parte de xafel ansorn, que coge todos esos datos que están guardados en HDFS y ocupando espacio y relaentizando todo. Coge todos esos datos y los ordena y los agrupas por claves iguales. Preferentemente que una clave vaya toda entera al mismo reducer. Si se puede, si no se puede, pues tendrá que ir a dos reducer. Pero lo intenta compactar todo lo más o menos posible. Esa parte se encarga jadub y esos datos todos ordenados por clave no por valor solo por clave. Si lasas el mape de 30 veces igual te lo sordena la misma clave, te la ordena de manera distinta las 30 veces. Porque un mape ha acabado antes porque estaba en un ordenador más rápido y ya emitió los mappers rápido o lo que fuera. No necesaria no estar garantizado que vayan en el mismo orden. Es curioso pensar como cuando lees la documentación de jadub de mongo de vez, también acaba diciendo que los resultados no siempre van en el mismo orden. Porque si tiras mucho mucho mucho mucho mucho mucho de libro hay una cosa como esta distribuida. Para nosotros siempre nos van a llegar en el mismo orden, ejecutando mongo en una máquina. No pasa nada, pero si tuviéramos el mongo replicado o con sardin o con tal, no podríamos garantizar que los resultados que cumplan en la condición nos vengan del mismo orden. ¿Por qué? Por esto. Entonces llegan esas parejas de clave valor, importante parejas de clave valor, que es lo que sale de los mappers a los reducios. Y los reducios ya hemos visto cómo podemos pasar del valor, sólo quedamos con la clave. La clave sí que tenemos que pillarla porque ver cuando cambiamos de la clave a otra. Podemos pasar de la clave, podemos utilizarla o podemos procesarlo de una manera un poco más compleja como estos colores de la pach. Utilizando estructuras de Python o cosas más complejas. Durante todo este trayecto vimos que a lo mejor se nos quedaba corto las herramientas que teníamos de Python. Algunos de vosotros para las letras a lo mejor es alibrería. Esa librería que utilizaste igual no está instalada en los nodos del claste de Amazon y no es va a funcionar vuestro mapper. Porque si utilizando una librería que ese contenedor que está allí en un nodo en Wisconsin no la tiene, entonces no la puede ejecutar. ¿Cuál es la manera para solucionar esto? Pues los entornos de Python, para eso están guay. Tu creas el entorno, se crea una carpeta dentro de tu proyecto y ahí es donde se está la Python, pandas y todas las cosas que tú quieras. Para que esa carpeta vayas son cientos de archivos lo más práctico es comprimirla y ajuntarla en el trabajo de Jadup streaming. Menos file y ajuntas ese archivo. ¿Cómo lo descomprimimos y activamos el entorno? Pues directamente no podamos, entonces hay que hacer trampa en el mapper o en el reducer o los dos si lo necesitas. Porque el mapper y el reducer no se tienen por qué ejecutar en el mismo contenedor. Primero van los mappers, dejando los datos de, para ejaclar el valor, se barajan, se ordenan, quedan en HDFS y después allá donde hayan quedado en HDFS que pueden ser en distintos nodos, porque es una nueva escritura en HDFS. Esos nodos donde estén esos resultados partiales, ahí es donde se va a crear el nuevo contenedor para el reducer. Si me seguís, te voy a ir la montanita y el último. Lo he dicho, se pueden ejecutar en contenedores distintos, entonces el truquillo está en crear un script que lo vas a ejecutar como si fuera tu mapper o tu reducer, que se encargue de ver si sacarte el truquillo, si está el entorno creada y por último cuando el entorno activado, lanza el mapper que es ajuntada. Esta parte es tal vez la más compleja y la que estaría guay probada en un entorno más grande. Pero no es la importante, porque de aquí no vamos a saber sabiendo programar más precios para ir a Amazon y hacerlo al vuelo. La idea es que salgamos aquí sabiendo que hay esta forma de programar indistribuido que consiste en analizar el problema y saber cómo partirlo y cómo juntarlo. Todos sabemos hacer eso en un listado de 20 entradas, pero si es de 25 millones de entradas, igual es más complicado partir. Todos sabemos sumar, pero si tuvimos que hacer una suma de esa como el local y se equivalos programas de gror, pues nos costaría. La esencia de este saben, aparentemente puede parecer difícil, porque lo mejor hay muchas preguntas así de mapes, pero para nada es mi intención que sepais programar lo en Python, escrito un papel en blanco. Mi intención es, tú ahora podrías hablar de tú a tú con alguien que se dedicará esto, de cómo lo hace, de qué enfoque le darías tú, de si él te lo explica entender, ¿qué hace? ¿Por qué lo hace? ¿Por qué le da más peso al mapper? ¿Por qué le da más peso al reducer? ¿Por qué al final no utiliza un reducer y prefiero hacer un script? ¿Por qué los datos son pequeñitos? ¿Por qué ya directamente se salta esto justo? ¿No me vas caso? ¿Por qué se salta el mapper? ¿Por qué ya sabe que los datos vienen en pareja clave valor ordenado? Pues esto es mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi mi Pues si no hay preguntas lo que podemos hacer es si os surge alguna cosa pues ponerla en el foro. Vale que el foro yo creo que es el sitio de cuadro porque casi seguro no hablaríamos de código y casi seguro hablaríamos un poco más de pues como la comestación que tenemos antes de yo utilizaría un conjunto yo no utilizaría una variable para controlar esto que estaba está muy bueno. Bueno pues nada cerramos por hoy entonces nos vemos la próxima semana ya Caracana. Bueno, bueno fin de semana a todos entonces. Ciao, ciao.