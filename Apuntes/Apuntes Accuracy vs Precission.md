### 游댳 **Accuracy (Exactitud)** vs. **Precision (Precisi칩n)**

Ambas son **m칠tricas de evaluaci칩n** utilizadas para medir el rendimiento de un modelo de clasificaci칩n, pero se enfocan en aspectos diferentes de las predicciones. A continuaci칩n, te explico sus diferencias clave:

---

### 1. **Accuracy (Exactitud)**

**Definici칩n:**  
La exactitud mide la **proporci칩n de predicciones correctas** sobre el total de predicciones realizadas. Es una m칠trica simple que se calcula as칤:

\[
\text{Accuracy} = \frac{\text{Predicciones correctas}}{\text{Total de predicciones}}
\]

**F칩rmula:**
\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]
Donde:
- **TP (True Positives)**: Verdaderos positivos
- **TN (True Negatives)**: Verdaderos negativos
- **FP (False Positives)**: Falsos positivos
- **FN (False Negatives)**: Falsos negativos

**Cuando usarla:**  
La **exactitud** es 칰til cuando el conjunto de datos est치 **balanceado**, es decir, cuando las clases positivas y negativas est치n igualmente distribuidas.

**Ejemplo:**
Si un modelo predice correctamente que 90 de 100 pacientes est치n sanos, pero falla en detectar a 10 con alguna enfermedad, la **exactitud** podr칤a ser bastante alta, pero el modelo estar칤a mal porque no detect칩 a los enfermos.

---

### 2. **Precision (Precisi칩n)**

**Definici칩n:**  
La **precisi칩n** mide la proporci칩n de **predicciones positivas correctas** sobre todas las predicciones positivas realizadas. Es decir, de todas las veces que el modelo predijo que algo es positivo, 쯖u치ntas veces fue realmente correcto?

\[
\text{Precision} = \frac{\text{TP}}{\text{TP + FP}}
\]

**F칩rmula:**
\[
\text{Precision} = \frac{TP}{TP + FP}
\]

**Cuando usarla:**  
La **precisi칩n** es especialmente 칰til cuando te interesa minimizar los **falsos positivos**, es decir, cuando un error en el que el modelo predice un positivo err칩neo es m치s costoso que predecir un negativo err칩neo.

**Ejemplo:**  
En un modelo de **detecci칩n de spam**, donde te interesa saber cu치ntos de los correos etiquetados como spam **realmente lo son**, la **precisi칩n** es m치s relevante. Un **falso positivo** (marcar un correo leg칤timo como spam) es m치s problem치tico que un **falso negativo** (dejar pasar un correo de spam).

---

### 游댳 **Diferencias clave:**

| M칠trica        | F칩rmula                                      | 쮺u치ndo usarla?                                                   |
|----------------|----------------------------------------------|-------------------------------------------------------------------|
| **Accuracy**    | \(\frac{TP + TN}{TP + TN + FP + FN}\)         | Conjuntos de datos balanceados.                                   |
| **Precision**   | \(\frac{TP}{TP + FP}\)                        | Cuando los falsos positivos son costosos o problem치ticos.         |

---

### **Resumen:**

- **Accuracy (Exactitud)** mide cu치n bien lo hace el modelo en general, considerando todas las predicciones correctas. Es 칰til cuando las clases est치n equilibradas.
  
- **Precision (Precisi칩n)** mide cu치ntos de los positivos predichos son realmente correctos. Es crucial cuando los falsos positivos son costosos o problem치ticos.

---

쯊e gustar칤a m치s detalles sobre alguna de estas m칠tricas o ejemplos de c칩mo calcularlas en un modelo espec칤fico? 游땕