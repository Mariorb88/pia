{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7685babe",
   "metadata": {},
   "source": [
    "\n",
    "# Explicaci√≥n paso a paso de una Red Neuronal Convolucional con PyTorch (MNIST)\n",
    "\n",
    "Este notebook recoge una conversaci√≥n educativa sobre c√≥mo funciona una red neuronal convolucional aplicada al dataset MNIST. Se detallan sus componentes, conceptos como padding, stride y el uso del par√°metro `dim=1` en la capa de salida.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0be196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class CNN(nn.Module):  # Definimos la red neuronal convolucional\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 7 * 7 * 64)  # Aplanamiento tras las capas convolucionales\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)  # Use log_softmax for cross-entropy loss\n",
    "        return x\n",
    "\n",
    "model = CNN()  # Instanciamos la red neuronal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae20bef0",
   "metadata": {},
   "source": [
    "\n",
    "## üìå Explicaci√≥n del modelo CNN\n",
    "\n",
    "- `conv1`: primera capa convolucional. Toma im√°genes de entrada con 1 canal (blanco y negro) y aplica 32 filtros 3x3. Usa `padding=1` para conservar el tama√±o.\n",
    "- `pool`: aplica `MaxPool2d(2, 2)`, que reduce el tama√±o de la imagen a la mitad (stride=2, tama√±o de filtro=2x2).\n",
    "- `conv2`: segunda convoluci√≥n que toma 32 canales y produce 64.\n",
    "- `fc1`: capa totalmente conectada que toma los 7x7x64 valores de salida y los reduce a 128 neuronas.\n",
    "- `fc2`: capa de salida con 10 neuronas, una por cada clase (d√≠gitos del 0 al 9).\n",
    "- `F.log_softmax(..., dim=1)`: convierte las salidas en log-probabilidades a lo largo de las 10 clases.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e8115",
   "metadata": {},
   "source": [
    "\n",
    "## üß± ¬øQu√© es el Padding?\n",
    "\n",
    "El `padding=1` en una convoluci√≥n con `kernel_size=3` mantiene el tama√±o de la imagen:\n",
    "\n",
    "$$\n",
    "\\text{Salida} = \\left\\lfloor \\frac{28 + 2 \\times 1 - 3}{1} \\right\\rfloor + 1 = 28\n",
    "$$\n",
    "\n",
    "Esto evita reducir el tama√±o muy r√°pidamente y conserva la informaci√≥n de los bordes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c890ae",
   "metadata": {},
   "source": [
    "\n",
    "## üèÉ‚Äç‚ôÇÔ∏è ¬øQu√© es el Stride?\n",
    "\n",
    "El `stride` es el n√∫mero de p√≠xeles que el filtro avanza cada vez. Si `stride=1`, se mueve de a un p√≠xel; si `stride=2`, se salta uno. A mayor stride, menor tama√±o de salida.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d058f8",
   "metadata": {},
   "source": [
    "\n",
    "## üéØ ¬øPor qu√© `dim=1` en `F.log_softmax(..., dim=1)`?\n",
    "\n",
    "En una red de clasificaci√≥n, la salida t√≠pica del modelo tiene forma `[batch_size, num_classes]`, por ejemplo `[64, 10]`.\n",
    "\n",
    "- `dim=1` aplica `softmax` por **fila**, es decir, para cada ejemplo en el batch.\n",
    "- Esto normaliza las 10 clases para cada imagen, convirti√©ndolas en probabilidades.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
